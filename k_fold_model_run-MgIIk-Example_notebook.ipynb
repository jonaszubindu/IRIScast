{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training on spectral line Mg II h&k - Example notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solar flares release their energy when twisted and twirled coronal magnetic field loops reconnect to form an energetically more favorable configuration. The twisting of these magnetic field loops is driven by the convective motion in the solar atmosphere below the $\\beta<1$ surface. Due to the frozen in condition the magnetic field can only reconnect and reconfigure above the $\\beta=1$ surface. However, it is only poorly understood how magnetic energy builds up over time in the emerging field loops without undergoing early reconnection, and what the necessary conditions are for reconnection to trigger a solar flare. Up to this day reliable data driven 3D magneto hydrodynamic models (3D-MHD) to model the evolution of an active region and predict flares from recorded initial conditions do not exist. At the same time, the computational costs of such a model would exceed current computational capabilities. Therefore, to investigate flares for early signs of an imminent eruption we investigate spectra in Mg II h&k, Si IV and CII collected by the small explorer satellite IRIS. Spectra contain height dependent informationa about the physical state of the atmospheric layer they form in. In case of Mg II h&k the formation height spans from the lower to upper chromosphere and in explosive events even into the transition region. The spectra from Si IV and C II form in the transition region, which lays between the Chromosphere and the Corona.\n",
    "\n",
    "### Fully connected neural networks\n",
    "\n",
    "<img src=\"NN_scheme.png\" width=\"600\" height=\"450\">\n",
    "\n",
    "Artificial Neural networks (ANN) for classification were first proposed in 1944 by Warren McCullough and Walter Pitts \\citep{fitch_1944}, but only became popular after the invention of backpropagation \\citep{Rumelhart_1986}, the advances in computation power in 2012, and creating ImageNet \\citep{ImageNet_2012} which could reliably classify images. The classical deep neural network is a fully connected network \\citep{bishop_1995}. It consists of an input layer containing the data to be classified or approximated, at least one hidden layer (deep) with an arbitrary number of neurons, and an output layer with a number of neurons appropriate to our classification problem. Fully connected means that the neurons between each layer are connected to each neuron in the previous and subsequent layer. For a binary classification task the output layer would consist of one or two neurons. Each neuron is equipped with an activation function, which is typically a rectified linear unit ReLU\n",
    "\\begin{equation}  \\label{int_num_test}  \n",
    "\\phi(x)  = \\begin{cases} \n",
    "0 & x \\le 0\\\\\n",
    "x & x > 0\\\\ \n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "for hidden layers and a sigmoid function \n",
    "\\begin{equation}\n",
    "   \\phi(x) = \\frac{1}{1+e^{-x}}\n",
    "\\end{equation}\n",
    "\n",
    "for the output neurons. Based on the universal approximation theorem \\citep{ZHOU_2020} we should be able to approximate any continuous function with a deep neural network containing at least one single hidden layer with an arbitrary number of neurons and non-linear activation functions on each neuron. However, in practice training a neural network is difficult and one has to carefully select the architecture, optimizer and loss function to balance convergence, training time as well as generalization, e. g. performance on unseen data of the network. This process is completely empirical and to our knowledge no solution to this ambiguity has been found yet. In case of classification what a neural network does is essentially warping and projecting the input space with non-linear transformations into lower dimensional representations, such that the data can be separated by a hyperplane or a set of hyperplanes into the desired amount of classes. The weights and biases are initialized randomly and get updated after each forward pass through backpropagation. Thereby, the output from the forward pass is compared to the desired output or label using a loss function. The loss function is dependent on the weights and biases, e. g. the parameters of the network and thus increases or decreases by adjusting them. Therefore, in order to improve our prediction model we update the weights and biases by computing the gradient of the loss function with respect to the weights and biases of our network. Since we cannot compute the gradient for our whole dataset on each forward pass, we choose a size of a representative random sample of our data called a minibatch to estimate the gradient of the loss function and update the parameters. The size of our minibatch can be estimated by the noise in the loss function and we chose sizes between 2400 to 6400 spectra per forward pass. To decide under which strategy our parameters should be updated to ensure convergence to the global minimum, we need to select an appropriate optimizer. In our case we used variants of Adam with and without weight decay, which is a learning rate adjusting algorithm that shows high performance in convergence speed and stability of the gradient \\citep{Adam}. Weight decay is controlled via a parameter set apriori and should prevent the model from overfitting. Overfitting is a state where the neural network “memorizes” the training data and performs well on it but does not generalize well to new data. To monitor the training process of a neural network we compare their loss both on the training and validation set which we split at about a 0.25:0.75 ratio. As soon as the loss on the validation set relative to the training set starts increasing while the loss on the training set remains decreasing or constant with training time, the network starts overfitting. To compare the performance on the validation set in parallel for each minibatch in the training set, we take a minibatch from the validation set matching the number of minibatches in the training set and feed it to the model after each training step, and record the learning curve.  By monitoring the learning curve we can observe overfitting and create adequate criteria for early stopping, e. g. to fall back on the best model state before overfitting. The learning curve is drawn with the loss on each minibatch, the black line represents the loss on the training set and the orange line the loss on the validation set. The blue line depicts the accuracy measured over the current validation minibatch. If the size of the minibatches is not representative enough, the learning curve becomes noisy with outliers. The same happens in case of a too high learning rate, since the model jumps too far in the parameter space and always misses the minimum. One sequence during which the model has seen the entire dataset is called an epoch. After each epoch the minibatches get reshuffled and the training sequence restarts. \n",
    "Better though is to prevent the model completely from overfitting by applying several techniques such as batch normalization, dropout, and the previously mentioned weight decay. Batch normalization normalizes each minibatch according to: \n",
    "\\begin{equation}\n",
    "    \\hat{x}_{i}^{(k)}=\\frac{x_{i}^{(k)}-\\mu_{B}^{(k)}}{\\sqrt{\\sigma_{B}^{(k)^{2}}+\\epsilon}}, \n",
    "\\end{equation}\n",
    "where $k \\in[1, d]$ and $ i \\in[1, m] $ and \n",
    "\\begin{equation}\n",
    "    \\mu_{B}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}, \\text { and } \\sigma_{B}^{2}=\\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}-\\mu_{B}\\right)^{2},\n",
    "\\end{equation}\n",
    "and thereby prevents the gradient from exploding through outliers, ensuring smooth fast convergence to the global minimum. Dropout randomly sets channels to zero not contributing to the output during a pass, ensuring equal training of all hidden layers and units. Weight decay is introduced through a regularization term in the loss function $\\frac{\\lambda}{2}\\|w_{i}\\|^2$. We use binary cross entropy as our loss function where we average over each batch:\n",
    "\\begin{equation}\n",
    "    L= \\frac{1}{m} \\sum_{i=1}^{m}-w_{i}\\left[y_{i} \\cdot \\log x_{i}+\\left(1-y_{i}\\right) \\cdot \\log \\left(1-x_{i}\\right)\\right],\n",
    "\\end{equation}\n",
    "with $x_i$ our model output and $y_i$ for the correct label of each spectrum $i$. To keep track of the best version of our network during training, we measure the models performance after each training epoch on the testing set and store the model in case it scored higher than the previously stored one. For very large testing sets this can increase the training time by a significant amount and therefore we estimate the best score from maximum $200'000$ samples and only compute the score on the full testing set with the final model.\n",
    "\n",
    "### Convolutional neural networks\n",
    "\n",
    "With the advance of image classification a different type of neural networks became popular, namely convolutional neural networks. First introduced by \\citep{hubel_1968}, the idea is to automatically derive features from the input, by using filters over a collection of pixels. Convolving the set of pixels to a single output and thereby making use of the correlation between adjacent pixels we get a sparsely connected network, easier to train and better generalizing to new data. The last part is usually still a fully connected network, taking the output of the convolutional layers. In this way, one can train filters to for instance recognize edges or round objects in images. Each type of filter creates a feature map highlighting the areas in the input image where certain patterns are more present. It also allows to reconstruct the type of information the network learned to base its decision on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will show how we trained and evaluated models on preprocessed and vae cleaned spectra from the Mg II h&k line. \n",
    "\n",
    "\n",
    "First let's import all the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "from IPython.core import display\n",
    "from IPython.core.display import Image\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.time import Time, TimeDelta\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.timeseries import TimeSeries\n",
    "from sunpy.time import parse_time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from IPython.display import HTML\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "\n",
    "import torch.multiprocessing\n",
    "\n",
    "import h5py\n",
    "\n",
    "from utils_features import *\n",
    "import utils as utils\n",
    "import utils_models_MgIIk as mdls\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the different obs ids and group them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids_Brandon_AR = ['20150518_143915_3860256971',\n",
    "                    '20150518_161415_3860256971',\n",
    "                    '20150521_185917_3800507454',\n",
    "                    '20150703_165917_3620006130',\n",
    "                    '20150704_100921_3860108354',\n",
    "                    '20150704_165917_3620006130',\n",
    "                    '20150728_151849_3660109122',\n",
    "                    '20150807_221421_3860259180',\n",
    "                    '20150809_061551_3860009180',\n",
    "                    '20150916_181744_3600101141',\n",
    "                    '20151017_003115_3660105403',\n",
    "                    '20150724_053523_3620109103',\n",
    "                    '20150130_112715_3860607366',\n",
    "                    '20150408_045717_3860107054',\n",
    "                    '20141128_210538_3860009154',\n",
    "                    '20141201_154438_3800008053',\n",
    "                    '20140329_201426_3820011652',\n",
    "                    '20140313_093521_3820109554']\n",
    "\n",
    "\n",
    "obs_ids_Brandon_PF = ['20141026_185250_3864111353',\n",
    "                    '20141107_093726_3860602088',\n",
    "                    '20140906_112339_3820259253',\n",
    "                    '20150821_160115_3660104044',\n",
    "                    '20140612_110933_3863605329',\n",
    "                    '20150312_054519_3860107053',\n",
    "                    '20140212_215458_3860257280',\n",
    "                    '20150311_044603_3860259280',\n",
    "                    '20141109_151704_3860258971',\n",
    "                    '20141027_205655_3864111353',\n",
    "                    '20140611_181927_3863605329',\n",
    "                    '20150622_170003_3660100039',\n",
    "                    '20141021_181052_3860261353',\n",
    "                    '20141025_145828_3880106953',\n",
    "                    '20140329_140938_3860258481',\n",
    "                    '20140910_112825_3860259453',\n",
    "                    '20141022_081850_3860261381',\n",
    "                    '20141027_140420_3860354980',\n",
    "                    '20150311_151947_3860107071']\n",
    "\n",
    "## Parameters for each line\n",
    "MgIIk = {'lambda_min' : 2794,\n",
    "         'lambda_max' : 2806,\n",
    "         'n_breaks' : 960,\n",
    "         'line' : \"Mg II k\",\n",
    "         'field' : \"NUV\",\n",
    "         'threshold' : 10\n",
    "        }\n",
    "\n",
    "\n",
    "\"\"\"Create the different sets for the k-fold cross validation\"\"\"\n",
    "\n",
    "num_of_repetitions = 5\n",
    "K = 5\n",
    "\n",
    "# Fix line here\n",
    "line = 'MgIIk'\n",
    "line_params = MgIIk\n",
    "\n",
    "#Setup your own paths\n",
    "\n",
    "path_cleaned_AR = f'~/cleaned/AR/'\n",
    "path_cleaned = f'~/cleaned/'\n",
    "path_cleaned_PF = f'~/cleaned/PF/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the different sets for the k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time # Careful! If you rerun this cell, you will create a new set of splits.\n",
    "\n",
    "y_neg = np.zeros([len(obs_ids_Brandon_AR)])\n",
    "y_pos_ = np.ones([len(obs_ids_Brandon_PF)])\n",
    "\n",
    "y_ = np.concatenate((y_pos_, y_neg), axis = 0)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "#Processing of green + yellow flare observations\n",
    "\n",
    "X_obs_ids = np.array(obs_ids_Brandon_PF + obs_ids_Brandon_AR)\n",
    "y_obs_ids = y_ # careful! choose well, since balance of labels is generated from this one\n",
    "\n",
    "\n",
    "\"\"\"Part to build the sets of labels for k-fold crossvalidation\"\"\"\n",
    "\n",
    "Label_set_all = {}\n",
    "\n",
    "obs_files = []\n",
    "splits = {}\n",
    "\n",
    "#Find all files with obs_ids in X_obs_ids\n",
    "\n",
    "for obs_np_file in os.listdir(path_cleaned_PF): # only takes the flares that could be processed and stored\n",
    "    obs_label = obs_np_file.split('.')[0][3:29] # IRIS obs ID\n",
    "    if obs_label in X_obs_ids:\n",
    "        obs_files.append(obs_np_file)\n",
    "\n",
    "\n",
    "for obs_np_file in os.listdir(path_cleaned_AR): # only takes the times that could be processed and stored\n",
    "    obs_label = obs_np_file.split('.')[0][3:29] # IRIS obs ID\n",
    "    if obs_label in X_obs_ids:\n",
    "        obs_files.append(obs_np_file)\n",
    "\n",
    "\n",
    "#create k-fold cross validation sets\n",
    "Label_set = {}\n",
    "\n",
    "for itter in tqdm(range(num_of_repetitions)):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=None)\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for train_index, test_index in skf.split(X_obs_ids, y_obs_ids):\n",
    "\n",
    "        # for a single split and rep make train and test sets (train cleaned, test uncleaned in general):\n",
    "\n",
    "        print(\"TRAIN set:\", X_obs_ids[train_index], \"TEST set:\", X_obs_ids[test_index])\n",
    "        train_set_, test_set_ = X_obs_ids[train_index], X_obs_ids[test_index]\n",
    "\n",
    "        files_train = []\n",
    "        files_test = []\n",
    "\n",
    "        for file_name in obs_files:\n",
    "\n",
    "            if np.any(file_name[3:29] == np.array(test_set_)):\n",
    "\n",
    "                files_test.append(file_name)\n",
    "\n",
    "            else:\n",
    "\n",
    "                files_train.append(file_name)\n",
    "\n",
    "        Label_set[str(k) + '_' + str(itter) + '_testing_obs_list'] = test_set_\n",
    "        Label_set[str(k) + '_' + str(itter) + '_training'] = files_train\n",
    "        Label_set[str(k) + '_' + str(itter) + '_testing'] = files_test\n",
    "\n",
    "        k += 1\n",
    "\n",
    "np.savez(path_cleaned + 'Label_set_5_5.npz', Label_set) # Careful! If you rerun this cell, you will create a new set of splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test, Training, Scoring\"\"\"\n",
    "\n",
    "def train(decision_model, optimizer, X):\n",
    "\n",
    "    local_batch = X[0]\n",
    "    local_labels = X[1]\n",
    "\n",
    "    # Transfer to GPU\n",
    "#     local_batch = local_batch.view(-1,1,line_params['n_breaks'])\n",
    "\n",
    "    local_batch, local_labels = local_batch.to(device, dtype= torch.float), local_labels.to(device, dtype= torch.float)\n",
    "\n",
    "    # Model computations\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_hat = decision_model(local_batch)\n",
    "    # Calculate loss\n",
    "    loss = criterion(y_hat.squeeze(), local_labels)\n",
    "\n",
    "    # Back pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.cpu().detach().numpy()\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(decision_model, V):\n",
    "\n",
    "    decision_model.eval()\n",
    "\n",
    "    local_batch = V[0]\n",
    "    local_labels = V[1]\n",
    "\n",
    "    local_batch, local_labels = local_batch.to(device, dtype= torch.float), local_labels.to(device, dtype= torch.float)\n",
    "\n",
    "\n",
    "    # Model computations\n",
    "    # Forward pass\n",
    "\n",
    "    y_hat = decision_model(local_batch)\n",
    "    # Calculate loss\n",
    "    loss = criterion(y_hat.squeeze(), local_labels)\n",
    "    valid_loss = loss.cpu().detach().numpy()\n",
    "\n",
    "    acc = accuracy_score(local_labels.cpu().detach().numpy().squeeze(), torch.round(y_hat).cpu().detach().numpy().squeeze())\n",
    "\n",
    "    return acc, valid_loss\n",
    "\n",
    "\n",
    "def compute_score(decision_models, validation_generator):\n",
    "\n",
    "    if not isinstance(decision_models, list):\n",
    "        decision_models = [decision_models]\n",
    "\n",
    "    [decision_model.eval() for decision_model in decision_models]\n",
    "\n",
    "    yhat_classes_list = [[] for n in range(len(decision_models))]\n",
    "\n",
    "    yhat_probs_list = [[] for n in range(len(decision_models))]\n",
    "\n",
    "    y_clean_obs_test_labels = []\n",
    "\n",
    "    for V in tqdm(validation_generator):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            local_batch = V[0]\n",
    "            local_labels = V[1]\n",
    "\n",
    "            # Transfer to GPU\n",
    "#             local_batch = local_batch.view(-1,1,line_params['n_breaks'])\n",
    "\n",
    "            local_batch, local_labels = local_batch.to(device, dtype= torch.float), local_labels.to(device, dtype= torch.float)\n",
    "\n",
    "            # predict probabilities for test set\n",
    "            yhat_list = [decision_model(local_batch) for decision_model in decision_models]\n",
    "            # predict classes for test set\n",
    "            _ = [yhat_classes.extend(np.array([ torch.round(yhat_prob[i]).cpu().detach().numpy() for i in range(len(yhat_prob)) ]).squeeze()) for yhat_prob, yhat_classes in zip(yhat_list, yhat_classes_list)]\n",
    "\n",
    "            _ = [yhat_probs.extend(yhat_prob.cpu().detach().numpy().squeeze()) for yhat_prob, yhat_probs in zip(yhat_list, yhat_probs_list)]\n",
    "\n",
    "            y_clean_obs_test_labels.extend(local_labels.cpu().detach().numpy().squeeze())\n",
    "\n",
    "    yhat_classes_list = [np.hstack(yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    yhat_probs_list = [np.hstack(yhat_probs) for yhat_probs in yhat_probs_list]\n",
    "\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = [accuracy_score(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print('Accuracy: ', accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = [precision_score(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print('Precision: ', precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = [recall_score(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print('Recall: ', recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = [f1_score(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print('F1 score: ', f1)\n",
    "    # kappa\n",
    "    kappa = [cohen_kappa_score(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print('Cohens kappa: ', kappa)\n",
    "    # ROC AUC\n",
    "    auc = [roc_auc_score(y_clean_obs_test_labels, yhat_probs) for yhat_probs in yhat_classes_list]\n",
    "    print('ROC AUC: ', auc)\n",
    "    # confusion matrix\n",
    "    matrices = [confusion_matrix(y_clean_obs_test_labels, yhat_classes) for yhat_classes in yhat_classes_list]\n",
    "    print(matrices)\n",
    "    # true skill score\n",
    "    TN = [matrix[0,0] for matrix in matrices]\n",
    "    FP = [matrix[0,1] for matrix in matrices]\n",
    "    FN = [matrix[1,0] for matrix in matrices]\n",
    "    TP = [matrix[1,1] for matrix in matrices]\n",
    "    tss_eval = [TP[n]/(TP[n]+FN[n]) - FP[n]/(FP[n]+TN[n]) for n in range(len(decision_models))]\n",
    "    print('TSS: ', tss_eval)\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa, auc, tss_eval\n",
    "\n",
    "    #trainer = Trainer(callbacks=[EarlyStopping(monitor=\"tss\")])\n",
    "\n",
    "\n",
    "\n",
    "def ROC_plot(decision_model, validation_generator, model_name):\n",
    "\n",
    "    decision_model.eval()\n",
    "\n",
    "    yhat_classes = []\n",
    "    yhat_probs = []\n",
    "\n",
    "    pos_class_dist = []\n",
    "    neg_class_dist = []\n",
    "    y_clean_obs_test_labels = []\n",
    "    coutner = 0\n",
    "    for V in tqdm(validation_generator):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            local_batch =V[0]\n",
    "            local_labels = V[1]\n",
    "\n",
    "            # Transfer to GPU\n",
    "#             local_batch = local_batch.view(-1,1,line_params['n_breaks'])\n",
    "\n",
    "            local_batch, local_labels = local_batch.to(device, dtype= torch.float), local_labels.to(device, dtype= torch.float)\n",
    "\n",
    "            # predict probabilities for test set\n",
    "            yhat_prob = decision_model(local_batch)\n",
    "            # predict classes for test set\n",
    "            yhat_classes.extend(np.array([ torch.round(yhat_prob[i]).cpu().detach().numpy() for i in range(len(yhat_prob)) ]).squeeze())\n",
    "\n",
    "            yhat_probs.extend(yhat_prob.cpu().detach().numpy().squeeze())\n",
    "            y_clean_obs_test_labels.extend(local_labels.cpu().detach().numpy().squeeze())\n",
    "            pos_class_dist.extend([ yhat_prob[j].cpu().detach().numpy().squeeze() for j in range(len(local_labels)) if local_labels[j]==1 ])\n",
    "            neg_class_dist.extend([ yhat_prob[j].cpu().detach().numpy().squeeze() for j in range(len(local_labels)) if local_labels[j]==0 ])\n",
    "\n",
    "    yhat_classes = np.hstack(yhat_classes)\n",
    "    yhat_probs = np.hstack(yhat_probs)\n",
    "\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_clean_obs_test_labels, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_clean_obs_test_labels, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_clean_obs_test_labels, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_clean_obs_test_labels, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_clean_obs_test_labels, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_clean_obs_test_labels, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    matrix = confusion_matrix(y_clean_obs_test_labels, yhat_classes)\n",
    "    print(matrix)\n",
    "    # true skill score\n",
    "    try:\n",
    "        # true skill score\n",
    "        TN = matrix[0,0]\n",
    "        FP = matrix[0,1]\n",
    "        FN = matrix[1,0]\n",
    "        TP = matrix[1,1]\n",
    "\n",
    "        if (FP == 0) and (TN == 0):\n",
    "            tss_eval = TP/(TP+FN)\n",
    "        elif (TP == 0) and (FN == 0):\n",
    "            tss_eval = -FP/(FP+TN)\n",
    "        else:\n",
    "            tss_eval = TP/(TP+FN) - FP/(FP+TN)\n",
    "    except Exception as exc:\n",
    "        if np.all(yhat_classes==1):\n",
    "            tss_eval = 1\n",
    "        elif np.all(yhat_classes==0):\n",
    "            tss_eval = 0\n",
    "        else:\n",
    "            print('something went wrong with the present observation', exc)\n",
    "            tss_eval = 0\n",
    "    print('TSS: %f' % tss_eval)\n",
    "\n",
    "    pos_class_dist = np.asarray( pos_class_dist )\n",
    "    neg_class_dist = np.asarray( neg_class_dist )\n",
    "\n",
    "    pos_class_dist = np.squeeze( pos_class_dist )\n",
    "    neg_class_dist = np.squeeze( neg_class_dist )\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    clrs='orange'\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------------\n",
    "    ax1 = plt.subplot(gs[0:, 0])\n",
    "    ax = sns.kdeplot( pos_class_dist, color='coral', label='pos',shade='r', zorder=1 )\n",
    "    ax = sns.kdeplot( neg_class_dist, color='powderblue', label='neg',shade='k', zorder=2 )\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "\n",
    "    plt.axvline(x=.5, c='k', linestyle='--')\n",
    "    plt.axvline(x=.2, c='k', linestyle='--')\n",
    "    plt.axvline(x=.8, c='k', linestyle='--')\n",
    "\n",
    "    plt.arrow(.2, 5.5, 0.2, 0, length_includes_head=True,\n",
    "              head_width=0.3, head_length=0.02, color='k')\n",
    "    plt.arrow(.5, 5.5, 0.2, 0, length_includes_head=True,\n",
    "              head_width=0.3, head_length=0.02, color='k')\n",
    "    plt.arrow(.8, 5.5, 0.2, 0, length_includes_head=True,\n",
    "              head_width=0.3, head_length=0.02, color='k')\n",
    "\n",
    "    ax.text(.25, 3, 'A', style='italic',\n",
    "            bbox={'facecolor': 'b', 'alpha': 0.3, 'pad': 8})\n",
    "    ax.text(.55, 3, 'B', style='italic',\n",
    "            bbox={'facecolor': 'orange', 'alpha': 0.3, 'pad': 8})\n",
    "    ax.text(.85, 3, 'C', style='italic',\n",
    "            bbox={'facecolor': 'green', 'alpha': 0.3, 'pad': 8})\n",
    "\n",
    "    plt.ylabel('density function')\n",
    "    plt.xlabel('score')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Class score distribution for the best model')\n",
    "\n",
    "    ax1 = plt.subplot(gs[0:, 1])\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import auc\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_clean_obs_test_labels, yhat_probs)\n",
    "    auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label = 'AA' + ' (area = {:.3f})'.format(auc),\n",
    "             c='k')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    p1 = abs(thresholds - .2).argmin()\n",
    "    p2 = abs(thresholds - .5).argmin()\n",
    "    p3 = abs(thresholds - .8).argmin()\n",
    "\n",
    "    posA = [fpr[p1], tpr[p1]]\n",
    "    posB = [fpr[p2], tpr[p2]]\n",
    "    posC = [fpr[p3], tpr[p3]]\n",
    "\n",
    "    plt.scatter(posA[0], posA[1], s=80)\n",
    "    plt.scatter(posB[0], posB[1], s=80)\n",
    "    plt.scatter(posC[0], posC[1], s=80)\n",
    "\n",
    "    plt.locator_params(axis='x', nbins=2)\n",
    "    plt.locator_params(axis='y', nbins=2)\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#     fig.savefig(f'{save_path_stats}_{model_name}.png')\n",
    "\n",
    "    return accuracy, precision, recall, f1, kappa, auc, tss_eval\n",
    "\n",
    "# Functions for plotting and animation:\n",
    "def anim_intensity_slit_movie(obs_cls, plot_arr, max_intensity = None, save_path=None):\n",
    "\n",
    "    # get irisreader observation instance\n",
    "    obs_id = obs_cls.obs_id\n",
    "    year = obs_id[:4]\n",
    "    month = obs_id[4:6]\n",
    "    day = obs_id[6:8]\n",
    "    pth = f'/sml/iris/{year}/{month}/{day}/{obs_id}'\n",
    "    obs = observation( pth, keep_null=True )\n",
    "\n",
    "    try:\n",
    "        sji = obs.sji('Si IV')\n",
    "        att = .25\n",
    "        cm = 'binary_r'\n",
    "    except Exception:\n",
    "        try:\n",
    "            sji = obs.sji('Mg II h/k')\n",
    "            att = .25\n",
    "            cm = 'binary_r'\n",
    "        except Exception:\n",
    "            sji = obs.sji('C II')\n",
    "            att = .4\n",
    "            cm = 'binary_r'\n",
    "\n",
    "    sji_times = sji.get_timestamps()\n",
    "    obs_time_0 = obs_cls.times[np.where(obs_cls.times>0)][0]\n",
    "    obs_time_end = obs_cls.times[np.where(obs_cls.times>0)][-1]\n",
    "    sj_0 = np.argmin(np.abs(obs_time_0 - sji_times))\n",
    "    sj_end = np.argmin(np.abs(obs_time_end - sji_times))\n",
    "    rast_ind = np.argmin(np.abs(obs_cls.times - sj_0), axis=1)\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    obs.close()\n",
    "\n",
    "    exptimes = np.array([hdr['EXPTIME'] for hdr in sji.headers]).reshape(-1,1,1)\n",
    "\n",
    "    # Generate initial figure for the animation with overplotted slit colors.\n",
    "    sji_exped = (sji[:,:,:].clip(min=0)/exptimes[:,:,:])**att\n",
    "    sji_exped[np.where(sji_exped == 0.)] = 5.0\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    im = plt.imshow(sji_exped[sj_0,:,:], cmap=cm, vmax=10)\n",
    "    slpos = raster_x_coord(obs_cls, sji, sj_0)\n",
    "    slpos_grid = [ [sl]*plot_arr.shape[2] for sl in slpos ] # slit x-coords for each spectra for a single raster\n",
    "    xcoords = np.asarray( [item for sublist in slpos_grid for item in sublist] ) # flatten nested list\n",
    "    ycoords = np.asarray( list(range(plot_arr.shape[2]))*plot_arr.shape[0] ) # y-coord for each spectra for a single raster\n",
    "    date_obs = parse_time(sji_times[sj_0], format='unix').to_datetime()\n",
    "    im.axes.set_title( \"Flare: {}  Frame: {}  Date-Time: {}\".format( obs_cls.obs_id, 0, date_obs ), fontsize=25, alpha=.8)\n",
    "    im.axes.set_xlabel( 'camera x', fontsize=25, alpha=.8 )\n",
    "    im.axes.set_ylabel( 'camera y', fontsize=25, alpha=.8 )\n",
    "    cmap = plt.cm.get_cmap('jet')\n",
    "\n",
    "\n",
    "    if not max_intensity:\n",
    "        max_intensity = np.max(plot_arr)*.2\n",
    "    colors = cmap(np.asarray([plot_arr[m,r_ind] for m, r_ind in enumerate(rast_ind)]).squeeze()/max_intensity)\n",
    "    if obs_cls.num_of_raster_pos != 1:\n",
    "        scat = plt.scatter(xcoords, ycoords, marker='s', s=15, c=colors.reshape(colors.shape[0]*colors.shape[1], 4), alpha=.3)\n",
    "    else:\n",
    "        scat = plt.scatter(xcoords, ycoords, marker='s', s=15, c=colors, alpha=.3)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    def init():\n",
    "        return im,\n",
    "\n",
    "    # animation function\n",
    "    def update(i, sji_times):\n",
    "        '''\n",
    "        Update the data for each successive raster.\n",
    "        '''\n",
    "        sjiind = sj_0 + i\n",
    "\n",
    "        sj_t = sji_times[sjiind]\n",
    "\n",
    "        rast_ind = np.argmin(np.abs(obs_cls.times - sj_t), axis=1)\n",
    "\n",
    "        slpos = raster_x_coord( obs_cls, sji, sjiind )\n",
    "        im.set_data(sji_exped[sjiind,:,:])\n",
    "        date_obs = parse_time(sj_t, format='unix').to_datetime()\n",
    "        im.axes.set_title( \"Flare: {}  Frame: {}  Date-Time: {}\".format( obs_cls.obs_id, i, date_obs ), fontsize=25, alpha=.8)\n",
    "        im.axes.set_xlabel( 'camera x', fontsize=25, alpha=.8 )\n",
    "        im.axes.set_ylabel( 'camera y', fontsize=25, alpha=.8 )\n",
    "        colors = cmap(np.asarray([plot_arr[m,r_ind] for m, r_ind in enumerate(rast_ind)]).squeeze()/max_intensity)\n",
    "        scat.set_offsets(np.asarray([xcoords, ycoords]).T)\n",
    "        if obs_cls.num_of_raster_pos != 1:\n",
    "            scat.set_color(colors.reshape(colors.shape[0]*colors.shape[1], 4))\n",
    "        else:\n",
    "            scat.set_color(colors)\n",
    "\n",
    "        return im\n",
    "\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, lambda i: update(i, sji_times), init_func=init, frames=sj_end-sj_0, interval=400)\n",
    "\n",
    "    if save_path:\n",
    "        anim.save(save_path)\n",
    "\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def raster_x_coord( obs_cls, sji, sjiind ):\n",
    "    '''\n",
    "    Returns n_raster slit positions ito pixels for a given SJI index.\n",
    "    '''\n",
    "    slitcoord_primary_x = sji.get_slit_pos(sjiind)-1\n",
    "    slit_offset_secondary = sji.headers[sjiind]['PZTX']/sji.headers[sjiind]['CDELT2'] # in pix coords\n",
    "    # This assumes that the PZT offsets remain constant for the entire observation\n",
    "    raster_offsets_secondary = np.asarray( [ obs_cls.hdrs.loc[i]['PZTX']/obs_cls.hdrs.loc[i]['CDELT2'] for i in range(obs_cls.num_of_raster_pos) ] )\n",
    "    # slit x position for each raster pos = position of primary - wedge tilt + fine scale secondary pztx\n",
    "    slpos = slitcoord_primary_x - slit_offset_secondary + raster_offsets_secondary\n",
    "\n",
    "    return slpos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get the labels of the different splits and load the indices from subsamples to be used later by the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data_labels(Label_set_filename, line):\n",
    "    path_cleaned = f'~/cleaned/'\n",
    "\n",
    "    Label_set_ = np.load(path_cleaned + Label_set_filename, allow_pickle=True)['arr_0'][()]\n",
    "\n",
    "    return Label_set_\n",
    "\n",
    "\n",
    "def Lazy_filehandler(files, line, max_samples=None):\n",
    "\n",
    "    X_PF_dict = {}\n",
    "    X_AR_dict = {}\n",
    "    label_file_IDs = []\n",
    "    label_indexs = []\n",
    "    y_labels = []\n",
    "\n",
    "    for file in files:\n",
    "        if file[:2] == 'PF':\n",
    "#             print(path_cleaned_PF + file)\n",
    "            with h5py.File(path_cleaned_PF + file, 'r') as f:\n",
    "\n",
    "                X_PF_dict[file] = f[\"im_arr_cleaned_QS\"].shape[0]\n",
    "\n",
    "        else:\n",
    "#             print(path_cleaned_AR + file)\n",
    "            with h5py.File(path_cleaned_AR + file, 'r') as f:\n",
    "\n",
    "                X_AR_dict[file] = f[\"im_arr_cleaned_QS\"].shape[0]\n",
    "\n",
    "    PF_samples = np.sum(np.array(list((X_PF_dict.values()))))\n",
    "    AR_samples = np.sum(np.array(list((X_AR_dict.values()))))\n",
    "\n",
    "    print(\"number of PF samples in total: \", PF_samples, \"number of AR samples in total: \", AR_samples)\n",
    "\n",
    "    if PF_samples > AR_samples:\n",
    "        upper_limit = AR_samples\n",
    "        major_limit = PF_samples\n",
    "\n",
    "        q = upper_limit/major_limit # factor between number of obs samples and sample size from each observation.\n",
    "\n",
    "        for file, nsamples in X_PF_dict.items():\n",
    "\n",
    "            sample_size = np.int(np.round(q*nsamples))\n",
    "            sample_indices = np.random.randint(0, nsamples, sample_size)\n",
    "            y_labels.extend(np.ones([sample_size]))\n",
    "            label_file_IDs.extend(['PF/'+file for sample_index in sample_indices])\n",
    "            label_indexs.extend([sample_index for sample_index in sample_indices])\n",
    "\n",
    "        nsamples_PF = len(y_labels)\n",
    "        print(\"number of samples PF: \", nsamples_PF)\n",
    "\n",
    "        for file, nsamples in X_AR_dict.items():\n",
    "\n",
    "            sample_indices = np.arange(0, nsamples)\n",
    "            y_labels.extend(np.zeros([nsamples]))\n",
    "            label_file_IDs.extend(['AR/'+file for sample_index in sample_indices])\n",
    "            label_indexs.extend([sample_index for sample_index in sample_indices])\n",
    "\n",
    "        nsamples_AR = len(y_labels) - nsamples_PF\n",
    "        print(\"number of samples AR: \", nsamples_AR)\n",
    "\n",
    "    else:\n",
    "        upper_limit = PF_samples\n",
    "        major_limit = AR_samples\n",
    "\n",
    "        q = upper_limit/major_limit # factor between number of obs samples and sample size from each observation.\n",
    "\n",
    "        for file, nsamples in X_AR_dict.items():\n",
    "\n",
    "            sample_size = np.int(np.round(q*nsamples))\n",
    "            sample_indices = np.random.randint(0, nsamples, sample_size)\n",
    "            y_labels.extend(np.zeros([sample_size]))\n",
    "            label_file_IDs.extend(['AR/'+file for sample_index in sample_indices])\n",
    "            label_indexs.extend([sample_index for sample_index in sample_indices])\n",
    "\n",
    "        nsamples_AR = len(y_labels)\n",
    "        print(\"number of samples AR: \", nsamples_AR)\n",
    "\n",
    "        for file, nsamples in X_PF_dict.items():\n",
    "\n",
    "            sample_indices = np.arange(0, nsamples)\n",
    "            y_labels.extend(np.ones([nsamples]))\n",
    "            label_file_IDs.extend(['PF/'+file for sample_index in sample_indices])\n",
    "            label_indexs.extend([sample_index for sample_index in sample_indices])\n",
    "\n",
    "        nsamples_PF = len(y_labels) - nsamples_AR\n",
    "        print(\"number of samples PF: \", nsamples_PF)\n",
    "\n",
    "    y_labels = np.array(y_labels)\n",
    "    label_file_IDs = np.array(label_file_IDs)\n",
    "    label_indexs = np.array(label_indexs)\n",
    "\n",
    "    if max_samples:\n",
    "        if max_samples > len(y_labels):\n",
    "            rand_inds = np.random.randint(0, len(y_labels), max_samples)\n",
    "        else:\n",
    "            rand_inds = np.random.randint(0, len(y_labels), max_samples)\n",
    "        y_labels = y_labels[rand_inds]\n",
    "        label_file_IDs = label_file_IDs[rand_inds]\n",
    "        label_indexs = label_indexs[rand_inds]\n",
    "\n",
    "    print(\"number of samples used (both PF + AR) label_IDs and y_labels: \", len(label_indexs), len(y_labels))\n",
    "\n",
    "    return label_file_IDs, label_indexs, y_labels\n",
    "\n",
    "def Lazy_filehandler_no_sampling(files, line):\n",
    "\n",
    "    X_PF_dict = {}\n",
    "    X_AR_dict = {}\n",
    "    label_file_IDs = []\n",
    "    label_indexs = []\n",
    "    y_labels = []\n",
    "\n",
    "    for file in files:\n",
    "        if file[:2] == 'PF':\n",
    "#             print(path_cleaned_PF + file)\n",
    "            with h5py.File(path_cleaned_PF + file, 'r') as f:\n",
    "\n",
    "                X_PF_dict[file] = f[\"im_arr_cleaned_QS\"].shape[0]\n",
    "\n",
    "        else:\n",
    "#             print(path_cleaned_AR + file)\n",
    "            with h5py.File(path_cleaned_AR + file, 'r') as f:\n",
    "\n",
    "                X_AR_dict[file] = f[\"im_arr_cleaned_QS\"].shape[0]\n",
    "\n",
    "\n",
    "    PF_samples = np.sum(np.array(list((X_PF_dict.values()))))\n",
    "    AR_samples = np.sum(np.array(list((X_AR_dict.values()))))\n",
    "\n",
    "    print(\"number of PF samples in total: \", PF_samples, \"number of AR samples in total: \", AR_samples)\n",
    "\n",
    "    for file, nsamples in X_PF_dict.items():\n",
    "\n",
    "        sample_indices = np.arange(0, nsamples)\n",
    "        y_labels.extend(np.ones([nsamples]))\n",
    "        label_file_IDs.extend(['PF/'+file for sample_index in sample_indices])\n",
    "        label_indexs.extend(sample_indices)\n",
    "\n",
    "\n",
    "    for file, nsamples in X_AR_dict.items():\n",
    "\n",
    "        sample_indices = np.arange(0, nsamples)\n",
    "        y_labels.extend(np.zeros([nsamples]))\n",
    "        label_file_IDs.extend(['AR/'+file for sample_index in sample_indices])\n",
    "        label_indexs.extend(sample_indices)\n",
    "\n",
    "    y_labels = np.array(y_labels)\n",
    "    label_file_IDs = np.array(label_file_IDs)\n",
    "    label_indexs = np.array(label_indexs)\n",
    "\n",
    "    print(\"number of samples used (both PF + AR) label_IDs and y_labels: \", len(label_indexs), len(y_labels))\n",
    "\n",
    "    return label_file_IDs, label_indexs, y_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main body to train the models\n",
    "\n",
    "I am using a workaround for the \"Too many open files\" problem with the Dataloader. If you run this cell for long time and many models, then check regularly if the memory leak is filling the memory. Notice that four different models are trained and tested at a time. The train, test, and compute_score functions don't care about how many models are submitted, but the ROC plot only accepts one at a time. The model architectures we used for this analysis are:\n",
    "\n",
    "\n",
    "Model architectures single line experiments fully connected neural networks\n",
    "\n",
    "| Single Layer |                  |                  |                  |\n",
    "|--------------|------------------|------------------|------------------|\n",
    "|              | 1st hidden Layer |                  |                  |\n",
    "| Mg II h&k    | 10, Sigmoid      |                  |                  |\n",
    "| Si IV        | 10, Sigmoid      |                  |                  |\n",
    "| CII          | 10, Sigmoid      |                  |                  |\n",
    "| Two Layers   |                  |                  |                  |\n",
    "|              | 1st hidden Layer | 2nd hidden Layer |                  |\n",
    "| Mg II h&k    | 12, ReLU         | 8, Sigmoid       |                  |\n",
    "| Si IV        | 12, ReLU         | 8, Sigmoid       |                  |\n",
    "| CII          | 12, ReLU         | 8, Sigmoid       |                  |\n",
    "| Three Layers |                  |                  |                  |\n",
    "|              | 1st hidden Layer | 2nd hidden Layer | 3rd hidden Layer |\n",
    "| Mg II h&k    | 10, ReLU         | 12, ReLU         | 8, Sigmoid       |\n",
    "| Si IV        | 12, ReLU         | 10, ReLU         | 8, Sigmoid       |\n",
    "| CII          | 10, ReLU         | 12, ReLU         | 8, Sigmoid       |\n",
    "\n",
    "\n",
    "Model architectures single line experiments convolutional neural networks\n",
    "\n",
    "| ConvNet   |                                                              |                                                           |\n",
    "|-----------|--------------------------------------------------------------|-----------------------------------------------------------|\n",
    "|           | 1st convolutional layer                                      | 1st hidden layer                                          |\n",
    "| Mg II h&k | in ch.: 1, out ch.: 10, kernel size: 32, stride: 16, ReLU    | 6, Sigmoid                                                |\n",
    "| Si IV     | in ch.: 1, out ch.: 2, kernel size: 20, stride: 4, ReLU      | 12, Sigmoid                                               |\n",
    "| CII       | in ch.: 1, out ch.: 2, kernel size: 20, stride: 4,   ReLU    | 6, Sigmoid                                                |\n",
    "|           |                                                              |                                                           |\n",
    "|           | 2nd convolutional layer                                      | 2nd hidden layer                                          |\n",
    "|           | in ch.: 10, out ch.: 20,   kernel size: 10 , stride: 5, ReLU |                                                           |\n",
    "|           | in ch.: 2, out ch.: 4, kernel size: 16 , stride: 3, ReLU     | 8, Sigmoid                                                |\n",
    "|           | in ch.: 2, out ch.: 4, kernel size: 16, stride: 3,   ReLU    |                                                           |\n",
    "\n",
    "\n",
    "Model architecture line combination:\n",
    "\n",
    "| Line combinations |                          |\n",
    "|-------------------|--------------------------|\n",
    "|                   | 1st convolutional layer: | in ch.: 1, out ch.: 10, kernel size: 32, stride: 16, ReLU  |\n",
    "|                   | 2nd convolutional layer: | in ch.: 10, out ch.: 20, kernel size: 16 , stride: 8, ReLU |\n",
    "|                   | 3rd convolutional layer: | in ch.: 20, out ch.: 40, kernel size: 4 , stride:2, ReLU   |\n",
    "|                   | 1st hidden layer:        | 10, ReLU or Sigmoid                                        |\n",
    "|                   | 2nd hidden layer:        | 12, ReLU or Sigmoid                                        |\n",
    "|                   | 3rd hidden layer:        | 8, Sigmoid                                                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#all PF\n",
    "\n",
    "sharing_strategy = \"file_system\"\n",
    "torch.multiprocessing.set_sharing_strategy(sharing_strategy)\n",
    "\n",
    "def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "    torch.multiprocessing.set_sharing_strategy(sharing_strategy)\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(mdls)\n",
    "\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "line = 'MgIIk'\n",
    "line_params = MgIIk\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True # only works if input shape does not vary, optimizes the use of your hardware to run the training\n",
    "\n",
    "# keep track of the factor between train and validation batches\n",
    "\n",
    "batch_size_train = 6400\n",
    "batch_size_val = 6400\n",
    "\n",
    "\n",
    "Label_set = Load_data_labels('Label_set_5_5.npz', line)\n",
    "for itter in range(num_of_repetitions):\n",
    "    for k in range(K):\n",
    "\n",
    "        if ('decision_model_zbinden_test_uncleaned_non_sampled_Brandon_full_' + str(k) + '_' + str(itter)+'_TwoLayers.pt') in os.listdir(f'/sml/zbindenj/{line}/models/'):\n",
    "            print(itter, k)\n",
    "        else:\n",
    "            label_train = Label_set[str(k) + '_' + str(itter) + '_training']\n",
    "            label_test = Label_set[str(k) + '_' + str(itter) + '_testing']\n",
    "\n",
    "            label_file_IDs_train, label_indexs_train, y_labels_train = Lazy_filehandler_no_sampling(label_train, line)\n",
    "            training_set = mdls.Dataset_NN(label_file_IDs_train, label_indexs_train, y_labels_train, path_cleaned)\n",
    "\n",
    "            label_file_IDs_test, label_indexs_test, y_labels_test = Lazy_filehandler_no_sampling(label_test, line)\n",
    "            validation_set = mdls.Dataset_NN(label_file_IDs_test, label_indexs_test, y_labels_test, path_cleaned)\n",
    "\n",
    "            label_file_IDs_test, label_indexs_test, y_labels_test = Lazy_filehandler_no_sampling(label_test, line)\n",
    "            validation_set_fast = mdls.Dataset_NN(label_file_IDs_test, label_indexs_test, y_labels_test, path_cleaned)\n",
    "\n",
    "            save_path_models = f'~/models/decision_model_' + str(k) + '_' + str(itter)\n",
    "            save_path_stats = f'~/stats/decision_model_' + str(k) + '_' + str(itter)\n",
    "\n",
    "            # Parameters and Generators\n",
    "            params_train = {'batch_size': batch_size_train,\n",
    "                      'shuffle': True,\n",
    "                      'num_workers': 16,\n",
    "                      'worker_init_fn': set_worker_sharing_strategy,\n",
    "                      'persistent_workers': True}\n",
    "\n",
    "            training_generator = torch.utils.data.DataLoader(training_set, **params_train)\n",
    "\n",
    "            params_val = {'batch_size': np.int(np.floor(len(validation_set)/len(training_generator))),\n",
    "                      'shuffle': True,\n",
    "                      'num_workers': 16,\n",
    "                      'worker_init_fn': set_worker_sharing_strategy,\n",
    "                      'persistent_workers': True}\n",
    "\n",
    "            params_fast_val = {'batch_size': batch_size_val,\n",
    "                      'shuffle': True,\n",
    "                      'num_workers': 16,\n",
    "                      'worker_init_fn': set_worker_sharing_strategy,\n",
    "                      'persistent_workers': True}\n",
    "\n",
    "            validation_generator = torch.utils.data.DataLoader(validation_set, **params_val)\n",
    "\n",
    "            validation_fast_generator = torch.utils.data.DataLoader(validation_set_fast, **params_fast_val)\n",
    "\n",
    "            optimizer = []\n",
    "            torch.cuda.empty_cache()\n",
    "            decision_model_SingleLayer = mdls.SingleLayer(line_params['n_breaks'], 10).to(device) # Initiate network\n",
    "            decision_model_TwoLayers = mdls.TwoLayers(line_params['n_breaks'], 12, 8).to(device) # Initiate network\n",
    "            decision_model_ThreeLayers = mdls.ThreeLayers(line_params['n_breaks'], 10, 12, 8).to(device) # Initiate network\n",
    "            decision_model_convnet = mdls.ConvNet(line_params['n_breaks'], 6).to(device) # Initiate network\n",
    "\n",
    "            decision_models = [decision_model_SingleLayer, decision_model_TwoLayers, decision_model_ThreeLayers, decision_model_convnet]\n",
    "\n",
    "            criterion = torch.nn.BCELoss(reduction='mean') # Use Binary cross-entropy as the loss function\n",
    "            optimizer.append(optim.Adam(decision_models[0].parameters(), lr=0.001, weight_decay=.001))\n",
    "            optimizer.append(optim.Adam(decision_models[1].parameters(), lr=0.001, weight_decay=.001))\n",
    "            optimizer.append(optim.Adam(decision_models[2].parameters(), lr=0.001, weight_decay=.001))\n",
    "            optimizer.append(optim.Adam(decision_models[3].parameters(), lr=0.001, weight_decay=.001))\n",
    "\n",
    "\n",
    "            # Loop over epochs\n",
    "            training_loss1 = []\n",
    "            validation_loss1 = []\n",
    "            accuracies_valid1 = []\n",
    "\n",
    "            training_loss2 = []\n",
    "            validation_loss2 = []\n",
    "            accuracies_valid2 = []\n",
    "\n",
    "            training_loss3 = []\n",
    "            validation_loss3 = []\n",
    "            accuracies_valid3 = []\n",
    "\n",
    "            training_loss4 = []\n",
    "            validation_loss4 = []\n",
    "            accuracies_valid4 = []\n",
    "\n",
    "            Mean_loss_train1 = []\n",
    "            Mean_loss_valid1 = []\n",
    "            Mean_loss_acc1 = []\n",
    "\n",
    "            Mean_loss_train2 = []\n",
    "            Mean_loss_valid2 = []\n",
    "            Mean_loss_acc2 = []\n",
    "\n",
    "            Mean_loss_train3 = []\n",
    "            Mean_loss_valid3 = []\n",
    "            Mean_loss_acc3 = []\n",
    "\n",
    "            Mean_loss_train4 = []\n",
    "            Mean_loss_valid4 = []\n",
    "            Mean_loss_acc4 = []\n",
    "\n",
    "            stats_current = {}\n",
    "            best_TSS0 = -1\n",
    "            best_TSS1 = -1\n",
    "            best_TSS2 = -1\n",
    "            best_TSS3 = -1\n",
    "\n",
    "\n",
    "            _ = [decision_model.train() for decision_model in decision_models]\n",
    "\n",
    "            _ = [decision_model.to(device) for decision_model in decision_models if (not next(decision_model.parameters()).is_cuda)]\n",
    "\n",
    "            break_ = False\n",
    "            n = 0\n",
    "            catch_ = 0\n",
    "            for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "                counter = 0\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "                # Training\n",
    "                for X, V in tqdm(zip(training_generator, validation_generator), total=len(training_generator)):\n",
    "\n",
    "                    train_loss1 = train(decision_model_SingleLayer, optimizer[0], X)\n",
    "                    train_loss2 = train(decision_model_TwoLayers, optimizer[1], X)\n",
    "                    train_loss3 = train(decision_model_ThreeLayers, optimizer[2], X)\n",
    "                    train_loss4 = train(decision_model_convnet, optimizer[3], X)\n",
    "\n",
    "                    training_loss1.append(train_loss1)\n",
    "                    training_loss2.append(train_loss2)\n",
    "                    training_loss3.append(train_loss3)\n",
    "                    training_loss4.append(train_loss4)\n",
    "\n",
    "\n",
    "\n",
    "                    acc_valid1, valid_loss1 = test(decision_model_SingleLayer, V)\n",
    "                    acc_valid2, valid_loss2 = test(decision_model_TwoLayers, V)\n",
    "                    acc_valid3, valid_loss3 = test(decision_model_ThreeLayers, V)\n",
    "                    acc_valid4, valid_loss4 = test(decision_model_convnet, V)\n",
    "\n",
    "                    validation_loss1.append(valid_loss1)\n",
    "                    accuracies_valid1.append(acc_valid1)\n",
    "                    validation_loss2.append(valid_loss2)\n",
    "                    accuracies_valid2.append(acc_valid2)\n",
    "                    validation_loss3.append(valid_loss3)\n",
    "                    accuracies_valid3.append(acc_valid3)\n",
    "                    validation_loss4.append(valid_loss4)\n",
    "                    accuracies_valid4.append(acc_valid4)\n",
    "\n",
    "\n",
    "                    counter += 1\n",
    "\n",
    "\n",
    "                    if ((counter % 200 == 199) and ((accuracies_valid1[-1]<.6) and epoch>5)): # make dependent on best model architecture\n",
    "\n",
    "\n",
    "                        accuracy, precision, recall, f1, kappa, auc, tss_eval = compute_score(decision_models, validation_fast_generator)\n",
    "\n",
    "                        stats_current = {'best epoch':epoch, 'accuracy':accuracy[0], 'precision':precision[0], 'recall':recall[0], 'f1':f1[0], 'kappa':kappa[0], 'auc':auc[0], 'TSS':tss_eval[0]}\n",
    "                        current_TSS = tss_eval[0]\n",
    "                        if current_TSS > best_TSS0: # only best model is stored\n",
    "                            best_TSS0 = current_TSS\n",
    "                            best_epoch0 = epoch\n",
    "                            torch.save(decision_model_SingleLayer.state_dict(), f'{save_path_models}_SingleLayer.pt')\n",
    "                            with open(f'{save_path_stats}_SingleLayer.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                        stats_current = {'best epoch':epoch, 'accuracy':accuracy[1], 'precision':precision[1], 'recall':recall[1], 'f1':f1[1], 'kappa':kappa[1], 'auc':auc[1], 'TSS':tss_eval[1]}\n",
    "                        current_TSS = tss_eval[1]\n",
    "                        if current_TSS > best_TSS1: # only best model is stored\n",
    "                            best_TSS1 = current_TSS\n",
    "                            best_epoch1 = epoch\n",
    "                            torch.save(decision_model_TwoLayers.state_dict(), f'{save_path_models}_TwoLayers.pt')\n",
    "                            with open(f'{save_path_stats}_TwoLayers.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                        stats_current = {'best epoch':epoch, 'accuracy':accuracy[2], 'precision':precision[2], 'recall':recall[2], 'f1':f1[2], 'kappa':kappa[2], 'auc':auc[2], 'TSS':tss_eval[2]}\n",
    "                        current_TSS = tss_eval[2]\n",
    "                        if current_TSS > best_TSS2: # only best model is stored\n",
    "                            best_TSS2 = current_TSS\n",
    "                            best_epoch2 = epoch\n",
    "                            torch.save(decision_model_ThreeLayers.state_dict(), f'{save_path_models}_ThreeLayers.pt')\n",
    "                            with open(f'{save_path_stats}_ThreeLayers.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                        stats_current = {'best epoch':epoch, 'accuracy':accuracy[3], 'precision':precision[3], 'recall':recall[3], 'f1':f1[3], 'kappa':kappa[3], 'auc':auc[3], 'TSS':tss_eval[3]}\n",
    "                        current_TSS = tss_eval[3]\n",
    "                        if current_TSS > best_TSS3: # only best model is stored\n",
    "                            best_TSS3 = current_TSS\n",
    "                            best_epoch3 = epoch\n",
    "                            torch.save(decision_model_convnet.state_dict(), f'{save_path_models}_convnet.pt')\n",
    "                            with open(f'{save_path_stats}_convnet.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "#                         if epoch >= 5:\n",
    "#                             break_ = True\n",
    "#                             pass\n",
    "\n",
    "\n",
    "                #After each epoch evaluate the model stats\n",
    "                accuracy, precision, recall, f1, kappa, auc, tss_eval = compute_score(decision_models, validation_fast_generator)\n",
    "\n",
    "                stats_current = {'best epoch':epoch, 'accuracy':accuracy[0], 'precision':precision[0], 'recall':recall[0], 'f1':f1[0], 'kappa':kappa[0], 'auc':auc[0], 'TSS':tss_eval[0]}\n",
    "                current_TSS = tss_eval[0]\n",
    "                if current_TSS > best_TSS0: # only best model is stored\n",
    "                    best_TSS0 = current_TSS\n",
    "                    best_epoch0 = epoch\n",
    "                    torch.save(decision_model_SingleLayer.state_dict(), f'{save_path_models}_SingleLayer.pt')\n",
    "                    with open(f'{save_path_stats}_SingleLayer.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                stats_current = {'best epoch':epoch, 'accuracy':accuracy[1], 'precision':precision[1], 'recall':recall[1], 'f1':f1[1], 'kappa':kappa[1], 'auc':auc[1], 'TSS':tss_eval[1]}\n",
    "                current_TSS = tss_eval[1]\n",
    "                if current_TSS > best_TSS1: # only best model is stored\n",
    "                    best_TSS1 = current_TSS\n",
    "                    best_epoch1 = epoch\n",
    "                    torch.save(decision_model_TwoLayers.state_dict(), f'{save_path_models}_TwoLayers.pt')\n",
    "                    with open(f'{save_path_stats}_TwoLayers.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                stats_current = {'best epoch':epoch, 'accuracy':accuracy[2], 'precision':precision[2], 'recall':recall[2], 'f1':f1[2], 'kappa':kappa[2], 'auc':auc[2], 'TSS':tss_eval[2]}\n",
    "                current_TSS = tss_eval[2]\n",
    "                if current_TSS > best_TSS2: # only best model is stored\n",
    "                    best_TSS2 = current_TSS\n",
    "                    best_epoch2 = epoch\n",
    "                    torch.save(decision_model_ThreeLayers.state_dict(), f'{save_path_models}_ThreeLayers.pt')\n",
    "                    with open(f'{save_path_stats}_ThreeLayers.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "\n",
    "                stats_current = {'best epoch':epoch, 'accuracy':accuracy[3], 'precision':precision[3], 'recall':recall[3], 'f1':f1[3], 'kappa':kappa[3], 'auc':auc[3], 'TSS':tss_eval[3]}\n",
    "                current_TSS = tss_eval[3]\n",
    "                if current_TSS > best_TSS3: # only best model is stored\n",
    "                    best_TSS3 = current_TSS\n",
    "                    best_epoch3 = epoch\n",
    "                    torch.save(decision_model_convnet.state_dict(), f'{save_path_models}_convnet.pt')\n",
    "                    with open(f'{save_path_stats}_convnet.p', 'wb') as f: pickle.dump(stats_current,f)\n",
    "\n",
    "                # SingleLayer\n",
    "\n",
    "                # summarize history for loss and accuracy\n",
    "                fig1, ax1 = plt.subplots(figsize=(15,4))\n",
    "                plt.title('model loss')\n",
    "                plt.xlabel('training mini batches')\n",
    "                plt.ylabel('loss')\n",
    "\n",
    "                l1, = plt.plot(np.arange(0, len(training_loss1)), np.asarray(training_loss1), color='black', alpha=.5)\n",
    "                l2, = plt.plot(np.arange(0, len(validation_loss1)), np.asarray(validation_loss1), color='coral', alpha=.5)\n",
    "                ax2 = ax1.twinx()\n",
    "                l3, = plt.plot(np.arange(0, len(accuracies_valid1)), np.asarray(accuracies_valid1), color='blue', alpha=.5)\n",
    "                plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "    #             fig1.savefig(f'{save_path_stats}_SingleLayer.pdf')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                # TwoLayers\n",
    "\n",
    "                # summarize history for loss and accuracy\n",
    "                fig2, ax2 = plt.subplots(figsize=(15,4))\n",
    "                plt.title('model loss')\n",
    "                plt.xlabel('training mini batches')\n",
    "                plt.ylabel('loss')\n",
    "\n",
    "                l1, = plt.plot(np.arange(0, len(training_loss2)), np.asarray(training_loss2), color='black', alpha=.5)\n",
    "                l2, = plt.plot(np.arange(0, len(validation_loss2)), np.asarray(validation_loss2), color='coral', alpha=.5)\n",
    "                ax2 = ax1.twinx()\n",
    "                l3, = plt.plot(np.arange(0, len(accuracies_valid2)), np.asarray(accuracies_valid2), color='blue', alpha=.5)\n",
    "                ax2.set_ylim([0,1])\n",
    "                plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "    #             fig2.savefig(f'{save_path_stats}_TwoLayers.pdf')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                # ThreeLayers\n",
    "\n",
    "                # summarize history for loss and accuracy\n",
    "                fig3, ax3 = plt.subplots(figsize=(15,4))\n",
    "                plt.title('model loss')\n",
    "                plt.xlabel('training mini batches')\n",
    "                plt.ylabel('loss')\n",
    "\n",
    "                l1, = plt.plot(np.arange(0, len(training_loss3)), np.asarray(training_loss3), color='black', alpha=.5)\n",
    "                l2, = plt.plot(np.arange(0, len(validation_loss3)), np.asarray(validation_loss3), color='coral', alpha=.5)\n",
    "                ax2 = ax1.twinx()\n",
    "                l3, = plt.plot(np.arange(0, len(accuracies_valid3)), np.asarray(accuracies_valid3), color='blue', alpha=.5)\n",
    "                plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "    #             fig3.savefig(f'{save_path_stats}_ThreeLayers.pdf')\n",
    "                plt.show()\n",
    "\n",
    "                # ConvNet\n",
    "\n",
    "                # summarize history for loss and accuracy\n",
    "                fig4, ax4 = plt.subplots(figsize=(15,4))\n",
    "                plt.title('model loss')\n",
    "                plt.xlabel('training mini batches')\n",
    "                plt.ylabel('loss')\n",
    "\n",
    "                l1, = plt.plot(np.arange(0, len(training_loss4)), np.asarray(training_loss4), color='black', alpha=.5)\n",
    "                l2, = plt.plot(np.arange(0, len(validation_loss4)), np.asarray(validation_loss4), color='coral', alpha=.5)\n",
    "                ax2 = ax1.twinx()\n",
    "                l3, = plt.plot(np.arange(0, len(accuracies_valid4)), np.asarray(accuracies_valid4), color='blue', alpha=.5)\n",
    "                plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "    #             fig4.savefig(f'{save_path_stats}_convnet.pdf')\n",
    "                plt.show()\n",
    "\n",
    "    ######################################################################################################################################################################################\n",
    "\n",
    "            # Last figure of learning curves\n",
    "\n",
    "            # SingleLayer\n",
    "\n",
    "            # summarize history for loss and accuracy\n",
    "            fig1, ax1 = plt.subplots(figsize=(15,4))\n",
    "            plt.title('model loss')\n",
    "            plt.xlabel('training mini batches')\n",
    "            plt.ylabel('loss')\n",
    "\n",
    "            l1, = plt.plot(np.arange(0, len(training_loss1)), np.asarray(training_loss1), color='black', alpha=.5)\n",
    "            l2, = plt.plot(np.arange(0, len(validation_loss1)), np.asarray(validation_loss1), color='coral', alpha=.5)\n",
    "            ax2 = ax1.twinx()\n",
    "            l3, = plt.plot(np.arange(0, len(accuracies_valid1)), np.asarray(accuracies_valid1), color='blue', alpha=.5)\n",
    "            plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "            fig1.savefig(f'{save_path_stats}_SingleLayer.pdf')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # TwoLayers\n",
    "\n",
    "            # summarize history for loss and accuracy\n",
    "            fig2, ax2 = plt.subplots(figsize=(15,4))\n",
    "            plt.title('model loss')\n",
    "            plt.xlabel('training mini batches')\n",
    "            plt.ylabel('loss')\n",
    "\n",
    "            l1, = plt.plot(np.arange(0, len(training_loss2)), np.asarray(training_loss2), color='black', alpha=.5)\n",
    "            l2, = plt.plot(np.arange(0, len(validation_loss2)), np.asarray(validation_loss2), color='coral', alpha=.5)\n",
    "            ax2 = ax1.twinx()\n",
    "            l3, = plt.plot(np.arange(0, len(accuracies_valid2)), np.asarray(accuracies_valid2), color='blue', alpha=.5)\n",
    "            ax2.set_ylim([0,1])\n",
    "            plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "            fig2.savefig(f'{save_path_stats}_TwoLayers.pdf')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # ThreeLayers\n",
    "\n",
    "            # summarize history for loss and accuracy\n",
    "            fig3, ax3 = plt.subplots(figsize=(15,4))\n",
    "            plt.title('model loss')\n",
    "            plt.xlabel('training mini batches')\n",
    "            plt.ylabel('loss')\n",
    "\n",
    "            l1, = plt.plot(np.arange(0, len(training_loss3)), np.asarray(training_loss3), color='black', alpha=.5)\n",
    "            l2, = plt.plot(np.arange(0, len(validation_loss3)), np.asarray(validation_loss3), color='coral', alpha=.5)\n",
    "            ax2 = ax1.twinx()\n",
    "            l3, = plt.plot(np.arange(0, len(accuracies_valid3)), np.asarray(accuracies_valid3), color='blue', alpha=.5)\n",
    "            plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "            fig3.savefig(f'{save_path_stats}_ThreeLayers.pdf')\n",
    "            plt.show()\n",
    "\n",
    "            # ConvNet\n",
    "\n",
    "            # summarize history for loss and accuracy\n",
    "            fig4, ax4 = plt.subplots(figsize=(15,4))\n",
    "            plt.title('model loss')\n",
    "            plt.xlabel('training mini batches')\n",
    "            plt.ylabel('loss')\n",
    "\n",
    "            l1, = plt.plot(np.arange(0, len(training_loss4)), np.asarray(training_loss4), color='black', alpha=.5)\n",
    "            l2, = plt.plot(np.arange(0, len(validation_loss4)), np.asarray(validation_loss4), color='coral', alpha=.5)\n",
    "            ax2 = ax1.twinx()\n",
    "            l3, = plt.plot(np.arange(0, len(accuracies_valid4)), np.asarray(accuracies_valid4), color='blue', alpha=.5)\n",
    "            plt.legend([l1,l2,l3],['loss', 'valid', 'acc'])\n",
    "            fig4.savefig(f'{save_path_stats}_convnet.pdf')\n",
    "            plt.show()\n",
    "\n",
    "            try:\n",
    "    #             exc_info = sys.exc_info()\n",
    "\n",
    "                decision_model_SingleLayer.load_state_dict(torch.load(f'{save_path_models}_SingleLayer.pt'))\n",
    "                decision_model_TwoLayers.load_state_dict(torch.load(f'{save_path_models}_TwoLayers.pt'))\n",
    "                decision_model_ThreeLayers.load_state_dict(torch.load(f'{save_path_models}_ThreeLayers.pt'))\n",
    "                decision_model_convnet.load_state_dict(torch.load(f'{save_path_models}_convnet.pt'))\n",
    "\n",
    "                ROC_plot(decision_model_SingleLayer, validation_fast_generator, 'SingleLayer')\n",
    "                ROC_plot(decision_model_TwoLayers, validation_fast_generator, 'TwoLayers')\n",
    "                ROC_plot(decision_model_ThreeLayers, validation_fast_generator, 'ThreeLayers')\n",
    "                ROC_plot(decision_model_convnet, validation_fast_generator, 'convnet')\n",
    "\n",
    "            except RuntimeError or FileNotFoundError:\n",
    "                pass # models that have not reached a complete epoch before going into overfitting are not stored\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of models over the whole set of splits\n",
    "Here the statistics are computed. If there are more or less than four models, blocks have to be added or removed here and the subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make overall statistics\n",
    "importlib.reload(mdls)\n",
    "\n",
    "Label_set = Load_data_labels('Label_set_5_5.npz', line)\n",
    "\n",
    "keys = ['k_itter',\n",
    "        'best_epoch',\n",
    "        'test_obs',\n",
    "        'n_train',\n",
    "        'n_test',\n",
    "        'TSS',\n",
    "        'ACC',\n",
    "        'recall',\n",
    "        'precision',\n",
    "        'kappa',\n",
    "        'f1',\n",
    "        'train_test_ratio']\n",
    "\n",
    "Failed = []\n",
    "\n",
    "sharing_strategy = \"file_system\"\n",
    "torch.multiprocessing.set_sharing_strategy(sharing_strategy)\n",
    "\n",
    "def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "    torch.multiprocessing.set_sharing_strategy(sharing_strategy)\n",
    "\n",
    "# CUDA for PyTorch\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "torch.backends.cudnn.benchmark = True # only works if input shape does not vary, optimizes the use of your hardware to run the training\n",
    "\n",
    "settype = 'test' # or 'test'\n",
    "\n",
    "all_stats_dic1 = {}\n",
    "all_stats_dic2 = {}\n",
    "all_stats_dic3 = {}\n",
    "all_stats_dic4 = {}\n",
    "\n",
    "\n",
    "\n",
    "train_obs_list = []\n",
    "test_obs_list = []\n",
    "n_train_list = []\n",
    "n_test_list = []\n",
    "kitter_list = []\n",
    "TSS_list1 = []\n",
    "ACC_list1 = []\n",
    "Recall_list1 = []\n",
    "Precision_list1 = []\n",
    "AUC_list1 = []\n",
    "Kappa_list1 = []\n",
    "F1_list1 = []\n",
    "train_test_ratio_list = []\n",
    "best_epoch_list1 = []\n",
    "\n",
    "\n",
    "best_epoch_list2 = []\n",
    "TSS_list2 = []\n",
    "ACC_list2 = []\n",
    "Recall_list2 = []\n",
    "Precision_list2 = []\n",
    "AUC_list2 = []\n",
    "Kappa_list2 = []\n",
    "F1_list2 = []\n",
    "\n",
    "\n",
    "best_epoch_list3 = []\n",
    "TSS_list3 = []\n",
    "ACC_list3 = []\n",
    "Recall_list3 = []\n",
    "Precision_list3 = []\n",
    "AUC_list3 = []\n",
    "Kappa_list3 = []\n",
    "F1_list3 = []\n",
    "\n",
    "\n",
    "best_epoch_list4 = []\n",
    "TSS_list4 = []\n",
    "ACC_list4 = []\n",
    "Recall_list4 = []\n",
    "Precision_list4 = []\n",
    "AUC_list4 = []\n",
    "Kappa_list4 = []\n",
    "F1_list4 = []\n",
    "\n",
    "\n",
    "for itter in range(num_of_repetitions):\n",
    "    for k in range(K):\n",
    "\n",
    "        all_stats_list1 = []\n",
    "        all_stats_list2 = []\n",
    "        all_stats_list3 = []\n",
    "        all_stats_list4 = []\n",
    "\n",
    "        save_path_stats = f'~/stats/decision_model_{k}_{itter}'\n",
    "        save_path_models = f'~/models/decision_model_{k}_{itter}'\n",
    "\n",
    "        all_obs_ids = obs_ids_Brandon_PF + obs_ids_Brandon_AR\n",
    "\n",
    "        label_train = Label_set[str(k) + '_' + str(itter) + '_training']\n",
    "        label_test = []\n",
    "        obs_ids_train = []\n",
    "        obs_ids_test = []\n",
    "\n",
    "        for obs_np_file in label_train:\n",
    "            obs_ids_train.append(obs_np_file.split('.')[0][3:29])\n",
    "\n",
    "        for obs_id in all_obs_ids:\n",
    "            if obs_id in obs_ids_train:\n",
    "                pass\n",
    "            else:\n",
    "                obs_ids_test.append(obs_id)\n",
    "\n",
    "        obs_ids_test = list(set(obs_ids_test))\n",
    "        label_train = []\n",
    "\n",
    "        for obs_np_file in os.listdir(path_cleaned_PF):\n",
    "            if obs_np_file.split('.')[0][3:29] in obs_ids_test:\n",
    "                label_test.append(obs_np_file)\n",
    "            elif obs_np_file.split('.')[0][3:29] in obs_ids_train:\n",
    "                label_train.append(obs_np_file)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        for obs_np_file in os.listdir(path_cleaned_AR):\n",
    "            if obs_np_file.split('.')[0][3:29] in obs_ids_test:\n",
    "                label_test.append(obs_np_file)\n",
    "            elif obs_np_file.split('.')[0][3:29] in obs_ids_train:\n",
    "                label_train.append(obs_np_file)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        label_file_IDs_train, label_indexs_train, y_labels_train = Lazy_filehandler_no_sampling(label_train, line)\n",
    "        label_file_IDs_test, label_indexs_test, y_labels_test = Lazy_filehandler_no_sampling(label_test, line)\n",
    "\n",
    "        failed=False\n",
    "        try:\n",
    "\n",
    "            validation_set = mdls.Dataset_NN(label_file_IDs_test, label_indexs_test, y_labels_test, path_cleaned)\n",
    "\n",
    "            # Parameters\n",
    "            params_val = {'batch_size': 6400,\n",
    "                      'shuffle': True,\n",
    "                      'num_workers': 16}\n",
    "\n",
    "            # Generators\n",
    "\n",
    "            validation_generator = torch.utils.data.DataLoader(validation_set, **params_val)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            decision_model_SingleLayer = mdls.SingleLayer(line_params['n_breaks'], 10).to(device) # Initiate network\n",
    "            decision_model_TwoLayers = mdls.TwoLayers(line_params['n_breaks'], 12, 8).to(device) # Initiate network\n",
    "            decision_model_ThreeLayers = mdls.ThreeLayers(line_params['n_breaks'], 10, 12, 8).to(device) # Initiate network\n",
    "            decision_model_convnet = mdls.ConvNet(line_params['n_breaks'], 6).to(device) # Initiate network\n",
    "\n",
    "            decision_model_SingleLayer.load_state_dict(torch.load(f'{save_path_models}_SingleLayer.pt', map_location=torch.device('cpu')))\n",
    "            decision_model_TwoLayers.load_state_dict(torch.load(f'{save_path_models}_TwoLayers.pt', map_location=torch.device('cpu')))\n",
    "            decision_model_ThreeLayers.load_state_dict(torch.load(f'{save_path_models}_ThreeLayers.pt', map_location=torch.device('cpu')))\n",
    "            decision_model_convnet.load_state_dict(torch.load(f'{save_path_models}_convnet.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "            decision_models = [decision_model_SingleLayer, decision_model_TwoLayers, decision_model_ThreeLayers, decision_model_convnet]\n",
    "            _ = [decision_model.to(device) for decision_model in decision_models if (not next(decision_model.parameters()).is_cuda)]\n",
    "\n",
    "\n",
    "            try:\n",
    "                with open(f'{save_path_stats}_SingleLayer_full_{settype}.p', 'rb') as f:\n",
    "                    stats1 = pickle.load(f)\n",
    "\n",
    "                with open(f'{save_path_stats}_TwoLayers_full_{settype}.p', 'rb') as f:\n",
    "                    stats2 = pickle.load(f)\n",
    "\n",
    "                with open(f'{save_path_stats}_ThreeLayers_full_{settype}.p', 'rb') as f:\n",
    "                    stats3 = pickle.load(f)\n",
    "\n",
    "                with open(f'{save_path_stats}_convnet_full_{settype}.p', 'rb') as f:\n",
    "                    stats4 = pickle.load(f)\n",
    "                print(mmm)\n",
    "\n",
    "            except Exception as exc:\n",
    "\n",
    "                print(exc)\n",
    "\n",
    "\n",
    "\n",
    "                accuracy, precision, recall, f1, kappa, auc, tss_eval = compute_score(decision_models, validation_generator)\n",
    "\n",
    "                with open(f'{save_path_stats}_SingleLayer.p', 'rb') as f:\n",
    "                    stats_single1 = pickle.load(f)\n",
    "\n",
    "                stats1 = {'k_itter': str(k)+'_'+str(itter),\n",
    "                         'test_obs': Label_set[str(k) + '_' + str(itter) + '_testing'],\n",
    "                         'best_epoch' : stats_single1['best epoch']+1,\n",
    "                         'n_train': len(label_file_IDs_train),\n",
    "                         'n_test': len(label_file_IDs_test),\n",
    "                         'TSS': tss_eval[0],\n",
    "                         'ACC': accuracy[0],\n",
    "                         'recall' : recall[0],\n",
    "                         'precision' : precision[0],\n",
    "                         'auc' : auc[0],\n",
    "                         'kappa' : kappa[0],\n",
    "                         'f1' : f1[0],\n",
    "                         'train_test_ratio': len(label_file_IDs_test)/(len(label_file_IDs_train)+len(label_file_IDs_test))}\n",
    "\n",
    "\n",
    "                with open(f'{save_path_stats}_SingleLayer_full_{settype}.p', 'wb') as f: pickle.dump(stats1,f)\n",
    "\n",
    "                with open(f'{save_path_stats}_TwoLayers.p', 'rb') as f:\n",
    "                    stats_single2 = pickle.load(f)\n",
    "\n",
    "    #             stats2 = {'best epoch':epoch, 'accuracy':accuracy[0], 'precision':precision[0], 'recall':recall[0], 'f1':f1[0], 'kappa':kappa[0], 'auc':auc[0], 'TSS':tss_eval[0]}\n",
    "\n",
    "                stats2 = {'k_itter': str(k)+'_'+str(itter),\n",
    "                         'test_obs': Label_set[str(k) + '_' + str(itter) + '_testing'],\n",
    "                         'best_epoch' : stats_single2['best epoch']+1,\n",
    "                         'n_train': len(label_file_IDs_train),\n",
    "                         'n_test': len(label_file_IDs_test),\n",
    "                         'TSS': tss_eval[1],\n",
    "                         'ACC': accuracy[1],\n",
    "                         'recall' : recall[1],\n",
    "                         'precision' : precision[1],\n",
    "                         'auc' : auc[1],\n",
    "                         'kappa' : kappa[1],\n",
    "                         'f1' : f1[1],\n",
    "                         'train_test_ratio': len(label_file_IDs_test)/(len(label_file_IDs_train)+len(label_file_IDs_test))}\n",
    "\n",
    "                with open(f'{save_path_stats}_TwoLayers_full_{settype}.p', 'wb') as f: pickle.dump(stats2,f)\n",
    "\n",
    "    #             print('TSS 2 list : ', TSS_list2)\n",
    "\n",
    "                with open(f'{save_path_stats}_ThreeLayers.p', 'rb') as f:\n",
    "                    stats_single3 = pickle.load(f)\n",
    "\n",
    "    #             stats3 = {'best epoch':epoch, 'accuracy':accuracy[0], 'precision':precision[0], 'recall':recall[0], 'f1':f1[0], 'kappa':kappa[0], 'auc':auc[0], 'TSS':tss_eval[0]}\n",
    "\n",
    "                stats3 = {'k_itter': str(k)+'_'+str(itter),\n",
    "                         'test_obs': Label_set[str(k) + '_' + str(itter) + '_testing'],\n",
    "                         'best_epoch' : stats_single3['best epoch']+1,\n",
    "                         'n_train': len(label_file_IDs_train),\n",
    "                         'n_test': len(label_file_IDs_test),\n",
    "                         'TSS': tss_eval[2],\n",
    "                         'ACC': accuracy[2],\n",
    "                         'recall' : recall[2],\n",
    "                         'precision' : precision[2],\n",
    "                         'auc' : auc[2],\n",
    "                         'kappa' : kappa[2],\n",
    "                         'f1' : f1[2],\n",
    "                         'train_test_ratio': len(label_file_IDs_test)/(len(label_file_IDs_train)+len(label_file_IDs_test))}\n",
    "\n",
    "                with open(f'{save_path_stats}_ThreeLayers_full_{settype}.p', 'wb') as f: pickle.dump(stats3,f)\n",
    "\n",
    "\n",
    "                with open(f'{save_path_stats}_convnet.p', 'rb') as f:\n",
    "                    stats_single4 = pickle.load(f)\n",
    "\n",
    "    #             stats4 = {'best epoch':epoch, 'accuracy':accuracy[0], 'precision':precision[0], 'recall':recall[0], 'f1':f1[0], 'kappa':kappa[0], 'auc':auc[0], 'TSS':tss_eval[0]}\n",
    "\n",
    "                stats4 = {'k_itter': str(k)+'_'+str(itter),\n",
    "                         'test_obs': Label_set[str(k) + '_' + str(itter) + '_testing'],\n",
    "                         'best_epoch' : stats_single4['best epoch']+1,\n",
    "                         'n_train': len(label_file_IDs_train),\n",
    "                         'n_test': len(label_file_IDs_test),\n",
    "                         'TSS': tss_eval[3],\n",
    "                         'ACC': accuracy[3],\n",
    "                         'recall' : recall[3],\n",
    "                         'precision' : precision[3],\n",
    "                         'auc' : auc[3],\n",
    "                         'kappa' : kappa[3],\n",
    "                         'f1' : f1[3],\n",
    "                         'train_test_ratio': len(label_file_IDs_test)/(len(label_file_IDs_train)+len(label_file_IDs_test))}\n",
    "\n",
    "                with open(f'{save_path_stats}_convnet_full_{settype}.p', 'wb') as f: pickle.dump(stats4,f)\n",
    "\n",
    "\n",
    "        except Exception as error:\n",
    "            Failed.append((itter,k))\n",
    "\n",
    "            print(error)\n",
    "            failed=True\n",
    "\n",
    "        try:\n",
    "            if failed:\n",
    "                pass\n",
    "            else:\n",
    "\n",
    "                kitter_list.append(stats1['k_itter'])\n",
    "                best_epoch_list1.append(stats1['best_epoch'])\n",
    "                test_obs_list.append(stats1['test_obs'])\n",
    "                n_train_list.append(stats1['n_train'])\n",
    "                n_test_list.append(stats1['n_test'])\n",
    "                TSS_list1.append(stats1['TSS'])\n",
    "                ACC_list1.append(stats1['ACC'])\n",
    "                Recall_list1.append(stats1['recall'])\n",
    "                Precision_list1.append(stats1['precision'])\n",
    "                AUC_list1.append(stats1['auc'])\n",
    "                Kappa_list1.append(stats1['kappa'])\n",
    "                F1_list1.append(stats1['f1'])\n",
    "                train_test_ratio_list.append(stats1['train_test_ratio'])\n",
    "\n",
    "                best_epoch_list2.append(stats2['best_epoch'])\n",
    "                TSS_list2.append(stats2['TSS'])\n",
    "                ACC_list2.append(stats2['ACC'])\n",
    "                Recall_list2.append(stats2['recall'])\n",
    "                Precision_list2.append(stats2['precision'])\n",
    "                AUC_list2.append(stats2['auc'])\n",
    "                Kappa_list2.append(stats2['kappa'])\n",
    "                F1_list2.append(stats2['f1'])\n",
    "\n",
    "                best_epoch_list3.append(stats3['best_epoch'])\n",
    "                TSS_list3.append(stats3['TSS'])\n",
    "                ACC_list3.append(stats3['ACC'])\n",
    "                Recall_list3.append(stats3['recall'])\n",
    "                Precision_list3.append(stats3['precision'])\n",
    "                AUC_list3.append(stats3['auc'])\n",
    "                Kappa_list3.append(stats3['kappa'])\n",
    "                F1_list3.append(stats3['f1'])\n",
    "\n",
    "                best_epoch_list4.append(stats4['best_epoch'])\n",
    "                TSS_list4.append(stats4['TSS'])\n",
    "                ACC_list4.append(stats4['ACC'])\n",
    "                Recall_list4.append(stats4['recall'])\n",
    "                Precision_list4.append(stats4['precision'])\n",
    "                AUC_list4.append(stats4['auc'])\n",
    "                Kappa_list4.append(stats4['kappa'])\n",
    "                F1_list4.append(stats4['f1'])\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(error)\n",
    "\n",
    "\n",
    "        for key in keys:\n",
    "            all_stats_list1.append(stats1[key])\n",
    "            all_stats_list2.append(stats2[key])\n",
    "            all_stats_list3.append(stats3[key])\n",
    "            all_stats_list4.append(stats4[key])\n",
    "\n",
    "        all_stats_dic1[str(k) +'_'+ str(itter)] = all_stats_list1\n",
    "        all_stats_dic2[str(k) +'_'+ str(itter)] = all_stats_list2\n",
    "        all_stats_dic3[str(k) +'_'+ str(itter)] = all_stats_list3\n",
    "        all_stats_dic4[str(k) +'_'+ str(itter)] = all_stats_list4\n",
    "\n",
    "\n",
    "sorted_itters1 = sorted(all_stats_dic1.keys(), key = lambda x: all_stats_dic1[x][3], reverse = True)\n",
    "sorted_itters2 = sorted(all_stats_dic2.keys(), key = lambda x: all_stats_dic2[x][3], reverse = True)\n",
    "sorted_itters3 = sorted(all_stats_dic3.keys(), key = lambda x: all_stats_dic3[x][3], reverse = True)\n",
    "sorted_itters4 = sorted(all_stats_dic4.keys(), key = lambda x: all_stats_dic4[x][3], reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitter = np.array(kitter_list)\n",
    "best_epoch1 = np.array(best_epoch_list1)\n",
    "test_obs = np.array(test_obs_list)\n",
    "n_train = np.array(n_train_list)\n",
    "n_test = np.array(n_test_list)\n",
    "TSS_1 = np.array(TSS_list1)\n",
    "ACC_1 = np.array(ACC_list1)\n",
    "Recall_1 = np.array(Recall_list1)\n",
    "Precision_1 = np.array(Precision_list1)\n",
    "AUC_1 = np.array(AUC_list1)\n",
    "Kappa_1 = np.array(Kappa_list1)\n",
    "F1_1 = np.array(F1_list1)\n",
    "train_test_ratio = np.array(train_test_ratio_list)\n",
    "\n",
    "best_epoch2 = np.array(best_epoch_list2)\n",
    "TSS_2 = np.array(TSS_list2)\n",
    "ACC_2 = np.array(ACC_list2)\n",
    "Recall_2 = np.array(Recall_list2)\n",
    "Precision_2 = np.array(Precision_list2)\n",
    "AUC_2 = np.array(AUC_list2)\n",
    "Kappa_2 = np.array(Kappa_list2)\n",
    "F1_2 = np.array(F1_list2)\n",
    "\n",
    "\n",
    "best_epoch3 = np.array(best_epoch_list3)\n",
    "TSS_3 = np.array(TSS_list3)\n",
    "ACC_3 = np.array(ACC_list3)\n",
    "Recall_3 = np.array(Recall_list3)\n",
    "Precision_3 = np.array(Precision_list3)\n",
    "AUC_3 = np.array(AUC_list3)\n",
    "Kappa_3 = np.array(Kappa_list3)\n",
    "F1_3 = np.array(F1_list3)\n",
    "\n",
    "\n",
    "best_epoch4 = np.array(best_epoch_list4)\n",
    "TSS_4 = np.array(TSS_list4)\n",
    "ACC_4 = np.array(ACC_list4)\n",
    "Recall_4 = np.array(Recall_list4)\n",
    "Precision_4 = np.array(Precision_list4)\n",
    "AUC_4 = np.array(AUC_list4)\n",
    "Kappa_4 = np.array(Kappa_list4)\n",
    "F1_4 = np.array(F1_list4)\n",
    "\n",
    "\n",
    "restr_ratio = np.where((train_test_ratio >= 0.05) & (train_test_ratio <= .5)) #actual true numbers\n",
    "\n",
    "kitter_reduced = kitter[restr_ratio]\n",
    "best_epoch_reduced1 = best_epoch1[restr_ratio]\n",
    "test_obs_reduced = test_obs[restr_ratio]\n",
    "n_train_reduced = n_train[restr_ratio]\n",
    "n_test_reduced = n_test[restr_ratio]\n",
    "TSS_reduced_1 = TSS_1[restr_ratio]\n",
    "ACC_reduced_1 = ACC_1[restr_ratio]\n",
    "Recall_reduced_1 = Recall_1[restr_ratio]\n",
    "Precision_reduced_1 = Precision_1[restr_ratio]\n",
    "AUC_reduced_1 = AUC_1[restr_ratio]\n",
    "Kappa_reduced_1 = Kappa_1[restr_ratio]\n",
    "F1_reduced_1 = F1_1[restr_ratio]\n",
    "train_test_ratio_reduced = train_test_ratio[restr_ratio]\n",
    "\n",
    "best_epoch_reduced2 = best_epoch2[restr_ratio]\n",
    "TSS_reduced_2 = TSS_2[restr_ratio]\n",
    "ACC_reduced_2 = ACC_2[restr_ratio]\n",
    "Recall_reduced_2 = Recall_2[restr_ratio]\n",
    "Precision_reduced_2 = Precision_2[restr_ratio]\n",
    "AUC_reduced_2 = AUC_2[restr_ratio]\n",
    "Kappa_reduced_2 = Kappa_2[restr_ratio]\n",
    "F1_reduced_2 = F1_2[restr_ratio]\n",
    "\n",
    "\n",
    "best_epoch_reduced3 = best_epoch3[restr_ratio]\n",
    "TSS_reduced_3 = TSS_3[restr_ratio]\n",
    "ACC_reduced_3 = ACC_3[restr_ratio]\n",
    "Recall_reduced_3 = Recall_3[restr_ratio]\n",
    "Precision_reduced_3 = Precision_3[restr_ratio]\n",
    "AUC_reduced_3 = AUC_3[restr_ratio]\n",
    "Kappa_reduced_3 = Kappa_3[restr_ratio]\n",
    "F1_reduced_3 = F1_3[restr_ratio]\n",
    "\n",
    "\n",
    "best_epoch_reduced4 = best_epoch4[restr_ratio]\n",
    "TSS_reduced_4 = TSS_4[restr_ratio]\n",
    "ACC_reduced_4 = ACC_4[restr_ratio]\n",
    "Recall_reduced_4 = Recall_4[restr_ratio]\n",
    "Precision_reduced_4 = Precision_4[restr_ratio]\n",
    "AUC_reduced_4 = AUC_4[restr_ratio]\n",
    "Kappa_reduced_4 = Kappa_4[restr_ratio]\n",
    "F1_reduced_4 = F1_4[restr_ratio]\n",
    "\n",
    "print(len(kitter), len(kitter_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,5), constrained_layout=False)\n",
    "rcParams['font.size'] = 16\n",
    "rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "gs = fig.add_gridspec(1, 5, hspace=0, wspace=0)\n",
    "ax1, ax2, ax3, ax4, ax5 = gs.subplots(sharex='col')#, sharey='row')\n",
    "\n",
    "[\"s\",\"P\", \"D\", \"*\", \"o\", \"v\", \"X\"]\n",
    "\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.set_xlabel('Single Layer', fontsize=23)\n",
    "# plt.errorbar([0, 1, 2, 3, 4, 5, 6], [np.mean(TSS_reduced_1), np.mean(ACC_reduced_1), np.mean(Recall_reduced_1), np.mean(Precision_reduced_1), np.mean(AUC_reduced_1), np.mean(Kappa_reduced_1), np.mean(F1_reduced_1)], yerr=[np.std(TSS_reduced_1), np.std(ACC_reduced_1), np.std(Recall_reduced_1), np.std(Precision_reduced_1), np.std(AUC_reduced_1), np.std(Kappa_reduced_1), np.std(F1_reduced_1)], lw=1.5, fmt=\"s\", capsize=3)\n",
    "\n",
    "ax1.errorbar([0], [np.mean(TSS_reduced_1)], yerr=[np.std(TSS_reduced_1)], lw=1.5, fmt=\"s\", c=\"red\", capsize=5, elinewidth=3, alpha=1, label='TSS')\n",
    "ax1.errorbar([1], [np.mean(ACC_reduced_1)], yerr=[np.std(ACC_reduced_1)], lw=1.5, fmt=\"P\", c=\"orange\", capsize=5, elinewidth=3, alpha=1, label='ACC')\n",
    "ax1.errorbar([2], [np.mean(Recall_reduced_1)], yerr=[np.std(Recall_reduced_1)], lw=1.5, fmt=\"D\", c=\"dodgerblue\", capsize=5, elinewidth=3, alpha=1, label='Recall')\n",
    "ax1.errorbar([3], [np.mean(Precision_reduced_1)], yerr=[np.std(Precision_reduced_1)], lw=1.5, fmt=\"*\", c=\"green\", capsize=5, elinewidth=3, alpha=1, label='Precision')\n",
    "ax1.errorbar([4], [np.mean(AUC_reduced_1)], yerr=[np.std(AUC_reduced_1)], lw=1.5, fmt=\"o\", c=\"royalblue\", capsize=5, elinewidth=3, alpha=1, label='AUC')\n",
    "ax1.errorbar([5], [np.mean(Kappa_reduced_1)], yerr=[np.std(Kappa_reduced_1)], lw=1.5, fmt=\"v\", c=\"mediumblue\", capsize=5, elinewidth=3, alpha=1, label='Kappa')\n",
    "ax1.errorbar([6], [np.mean(F1_reduced_1)], yerr=[np.std(F1_reduced_1)], lw=1.5, fmt=\"X\", c=\"brown\", capsize=5, elinewidth=3, alpha=1, label='F1')\n",
    "\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax1.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax1.tick_params(which='major', length=8,width=1.5, labelsize=23)\n",
    "ax1.tick_params(which='minor', length=5,width=1.5, labelsize=23)\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_xlim(-1,9)\n",
    "\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.set_xlabel('Two Layers', fontsize=23)\n",
    "# plt.errorbar([0, 1, 2, 3, 4, 5, 6], [np.mean(TSS_reduced_1), np.mean(ACC_reduced_1), np.mean(Recall_reduced_1), np.mean(Precision_reduced_1), np.mean(AUC_reduced_1), np.mean(Kappa_reduced_1), np.mean(F1_reduced_1)], yerr=[np.std(TSS_reduced_1), np.std(ACC_reduced_1), np.std(Recall_reduced_1), np.std(Precision_reduced_1), np.std(AUC_reduced_1), np.std(Kappa_reduced_1), np.std(F1_reduced_1)], lw=1.5, fmt=\"s\", capsize=3)\n",
    "\n",
    "l1 = ax2.errorbar([0], [np.mean(TSS_reduced_2)], yerr=[np.std(TSS_reduced_2)], lw=1.5, fmt=\"s\", c=\"red\", capsize=5, elinewidth=3, alpha=1, label='TSS')\n",
    "l2 = ax2.errorbar([1], [np.mean(ACC_reduced_2)], yerr=[np.std(ACC_reduced_2)], lw=1.5, fmt=\"P\", c=\"orange\", capsize=5, elinewidth=3, alpha=1, label='ACC')\n",
    "l3 = ax2.errorbar([2], [np.mean(Recall_reduced_2)], yerr=[np.std(Recall_reduced_2)], lw=1.5, fmt=\"D\", c=\"dodgerblue\", capsize=5, elinewidth=3, alpha=1, label='Recall')\n",
    "l4 = ax2.errorbar([3], [np.mean(Precision_reduced_2)], yerr=[np.std(Precision_reduced_2)], lw=1.5, fmt=\"*\", c=\"green\", capsize=5, elinewidth=3, alpha=1, label='Precision')\n",
    "l5 = ax2.errorbar([4], [np.mean(AUC_reduced_2)], yerr=[np.std(AUC_reduced_2)], lw=1.5, fmt=\"o\", c=\"royalblue\", capsize=5, elinewidth=3, alpha=1, label='AUC')\n",
    "l6 = ax2.errorbar([5], [np.mean(Kappa_reduced_2)], yerr=[np.std(Kappa_reduced_2)], lw=1.5, fmt=\"v\", c=\"mediumblue\", capsize=5, elinewidth=3, alpha=1, label='Kappa')\n",
    "l7 = ax2.errorbar([6], [np.mean(F1_reduced_2)], yerr=[np.std(F1_reduced_2)], lw=1.5, fmt=\"X\", c=\"brown\", capsize=5, elinewidth=3, alpha=1, label='F1')\n",
    "# plt.legend()\n",
    "\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticklabels([])\n",
    "ax2.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax2.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax2.tick_params(which='major', length=8,width=1.5)\n",
    "ax2.tick_params(which='minor', length=5,width=1.5)\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_xlim(-1,9)\n",
    "\n",
    "# ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.set_xlabel('Three Layers', fontsize=23)\n",
    "# plt.errorbar([0, 1, 2, 3, 4, 5, 6], [np.mean(TSS_reduced_1), np.mean(ACC_reduced_1), np.mean(Recall_reduced_1), np.mean(Precision_reduced_1), np.mean(AUC_reduced_1), np.mean(Kappa_reduced_1), np.mean(F1_reduced_1)], yerr=[np.std(TSS_reduced_1), np.std(ACC_reduced_1), np.std(Recall_reduced_1), np.std(Precision_reduced_1), np.std(AUC_reduced_1), np.std(Kappa_reduced_1), np.std(F1_reduced_1)], lw=1.5, fmt=\"s\", capsize=3)\n",
    "\n",
    "ax3.errorbar([0], [np.mean(TSS_reduced_3)], yerr=[np.std(TSS_reduced_3)], lw=1.5, fmt=\"s\", c=\"red\", capsize=5, alpha=1, elinewidth=3, label='TSS')\n",
    "ax3.errorbar([1], [np.mean(ACC_reduced_3)], yerr=[np.std(ACC_reduced_3)], lw=1.5, fmt=\"P\", c=\"orange\", capsize=5, alpha=1, elinewidth=3, label='ACC')\n",
    "ax3.errorbar([2], [np.mean(Recall_reduced_3)], yerr=[np.std(Recall_reduced_3)], lw=1.5, fmt=\"D\", c=\"dodgerblue\", capsize=5, alpha=1, elinewidth=3, label='Recall')\n",
    "ax3.errorbar([3], [np.mean(Precision_reduced_3)], yerr=[np.std(Precision_reduced_3)], lw=1.5, fmt=\"*\", c=\"green\", capsize=5, alpha=1, elinewidth=3, label='Precision')\n",
    "ax3.errorbar([4], [np.mean(AUC_reduced_3)], yerr=[np.std(AUC_reduced_3)], lw=1.5, fmt=\"o\", c=\"royalblue\", capsize=5, alpha=1, elinewidth=3, label='AUC')\n",
    "ax3.errorbar([5], [np.mean(Kappa_reduced_3)], yerr=[np.std(Kappa_reduced_3)], lw=1.5, fmt=\"v\", c=\"mediumblue\", capsize=5, alpha=1, elinewidth=3, label='Kappa')\n",
    "ax3.errorbar([6], [np.mean(F1_reduced_3)], yerr=[np.std(F1_reduced_3)], lw=1.5, fmt=\"X\", c=\"brown\", capsize=5, alpha=1, elinewidth=3, label='F1')\n",
    "# plt.legend()\n",
    "\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticklabels([])\n",
    "ax3.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax3.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax3.tick_params(which='major', length=8,width=1.5)\n",
    "ax3.tick_params(which='minor', length=5,width=1.5)\n",
    "ax3.set_ylim(0,1)\n",
    "ax3.set_xlim(-1,9)\n",
    "\n",
    "# ax4 = fig.add_subplot(gs[0, 3])\n",
    "ax4.set_xlabel('Convolutional Network', fontsize=23)\n",
    "# plt.errorbar([0, 1, 2, 3, 4, 5, 6], [np.mean(TSS_reduced_1), np.mean(ACC_reduced_1), np.mean(Recall_reduced_1), np.mean(Precision_reduced_1), np.mean(AUC_reduced_1), np.mean(Kappa_reduced_1), np.mean(F1_reduced_1)], yerr=[np.std(TSS_reduced_1), np.std(ACC_reduced_1), np.std(Recall_reduced_1), np.std(Precision_reduced_1), np.std(AUC_reduced_1), np.std(Kappa_reduced_1), np.std(F1_reduced_1)], lw=1.5, fmt=\"s\", capsize=3)\n",
    "\n",
    "ax4.errorbar([0], [np.mean(TSS_reduced_4)], yerr=[np.std(TSS_reduced_4)], lw=1.5, fmt=\"s\", c=\"red\", capsize=5, elinewidth=3, alpha=1, label='TSS')\n",
    "ax4.errorbar([1], [np.mean(ACC_reduced_4)], yerr=[np.std(ACC_reduced_4)], lw=1.5, fmt=\"P\", c=\"orange\", capsize=5, elinewidth=3, alpha=1, label='ACC')\n",
    "ax4.errorbar([2], [np.mean(Recall_reduced_4)], yerr=[np.std(Recall_reduced_4)], lw=1.5, fmt=\"D\", c=\"dodgerblue\", capsize=5, elinewidth=3, alpha=1, label='Recall')\n",
    "ax4.errorbar([3], [np.mean(Precision_reduced_4)], yerr=[np.std(Precision_reduced_4)], lw=1.5, fmt=\"*\", c=\"green\", capsize=5, elinewidth=3, alpha=1, label='Precision')\n",
    "ax4.errorbar([4], [np.mean(AUC_reduced_4)], yerr=[np.std(AUC_reduced_4)], lw=1.5, fmt=\"o\", c=\"royalblue\", capsize=5, elinewidth=3, alpha=1, label='AUC')\n",
    "ax4.errorbar([5], [np.mean(Kappa_reduced_4)], yerr=[np.std(Kappa_reduced_4)], lw=1.5, fmt=\"v\", c=\"mediumblue\", capsize=5, elinewidth=3, alpha=1, label='Kappa')\n",
    "ax4.errorbar([6], [np.mean(F1_reduced_4)], yerr=[np.std(F1_reduced_4)], lw=1.5, fmt=\"X\", c=\"brown\", capsize=5, elinewidth=3, alpha=1, label='F1')\n",
    "# plt.legend()\n",
    "\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticklabels([])\n",
    "ax4.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax4.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax4.tick_params(which='major', length=8, width=1.5)\n",
    "ax4.tick_params(which='minor', length=5, width=1.5)\n",
    "ax4.set_ylim(0,1)\n",
    "ax4.set_xlim(-1,9)\n",
    "\n",
    "# ax5 = fig.add_subplot(gs[0, 4])\n",
    "plt.legend([l1,l2,l3,l4,l5,l6,l7],['TSS','ACC','Recall','Precision','AUC','Kappa','F1'], prop={'size': 20})\n",
    "ax5.set_xticks([])\n",
    "ax5.set_yticks([])\n",
    "fig.savefig(f'/sml/zbindenj/{line}/stats/stats_validation.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig2 = plt.figure(figsize=(20,5), constrained_layout=False)\n",
    "rcParams['font.size'] = 16\n",
    "rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "gs = fig2.add_gridspec(1, 6)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 0])\n",
    "plt.ylabel('Train/Test ratio', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(train_test_ratio_reduced)], yerr=[np.std(train_test_ratio_reduced)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Train/Test ratio')\n",
    "sns.swarmplot(data=train_test_ratio_reduced, color=\"r\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "# ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "# ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 1])\n",
    "plt.ylabel('Number of test spectra', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(n_test_reduced)], yerr=[np.std(n_test_reduced)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Number of test spectra')\n",
    "sns.swarmplot(data=n_test_reduced, color=\"r\")\n",
    "# sns.boxplot( data=TSS_reduced_2, color=\"k\", boxprops=dict(alpha=.3))\n",
    "# sns.swarmplot(data=TSS_reduced_2, color=\"k\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "# ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "# ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 2])\n",
    "plt.ylabel('Number of epochs', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(best_epoch_reduced1)], yerr=[np.std(best_epoch_reduced1)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Number of epochs')\n",
    "sns.swarmplot(data=best_epoch_reduced1, color=\"r\")\n",
    "# sns.boxplot( data=TSS_reduced_2, color=\"k\", boxprops=dict(alpha=.3))\n",
    "# sns.swarmplot(data=TSS_reduced_2, color=\"k\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "ax.set_ylim([0,10])\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 3])\n",
    "plt.ylabel('Number of epochs', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(best_epoch_reduced2)], yerr=[np.std(best_epoch_reduced2)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Number of epochs')\n",
    "sns.swarmplot(data=best_epoch_reduced2, color=\"r\")\n",
    "# sns.boxplot( data=TSS_reduced_2, color=\"k\", boxprops=dict(alpha=.3))\n",
    "# sns.swarmplot(data=TSS_reduced_2, color=\"k\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "ax.set_ylim([0,10])\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 4])\n",
    "plt.ylabel('Number of epochs', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(best_epoch_reduced3)], yerr=[np.std(best_epoch_reduced3)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Number of epochs')\n",
    "sns.swarmplot(data=best_epoch_reduced3, color=\"r\")\n",
    "# sns.boxplot( data=TSS_reduced_2, color=\"k\", boxprops=dict(alpha=.3))\n",
    "# sns.swarmplot(data=TSS_reduced_2, color=\"k\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "ax.set_ylim([0,10])\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "ax = fig2.add_subplot(gs[0, 5])\n",
    "plt.ylabel('Number of epochs', fontsize=23)\n",
    "plt.errorbar([0], [np.mean(best_epoch_reduced4)], yerr=[np.std(best_epoch_reduced4)], lw=1.5, fmt=\"s\", c=\"k\", capsize=3, elinewidth=3, alpha=.7, label='Number of epochs')\n",
    "sns.swarmplot(data=best_epoch_reduced4, color=\"r\")\n",
    "# sns.boxplot( data=TSS_reduced_2, color=\"k\", boxprops=dict(alpha=.3))\n",
    "# sns.swarmplot(data=TSS_reduced_2, color=\"k\")\n",
    "# plt.scatter(np.zeros([3]), [np.mean(np.array(ACC_reduced_1)), np.max(np.array(ACC_reduced_1)), np.min(np.array(ACC_reduced_1))], c='r', s=100, marker='x')\n",
    "ax.set_xticks([])\n",
    "ax.set_ylim([0,10])\n",
    "ax.yaxis.set_major_locator(MultipleLocator(5))\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(.05))\n",
    "ax.tick_params(which='major', length=8,width=1.5)\n",
    "# ax.tick_params(which='minor', length=5,width=1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Jonas",
   "language": "python",
   "name": "venv_jonas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
